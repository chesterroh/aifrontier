---
episodeNumber: 80
title: "2026년은 과학의 해가 될까? AI와 과학"
description: "2025년은 클로드 코드(Claude Code) 출시와 함께 코딩의 해로 기억된다면, 다가오는 2026년은 AI에 의해 과학의 패러다임이 바뀌는 한 해가 될 것으로..."
publishedAt: 2026-01-28
duration: "57:27"
youtubeId: "P8hjiB709gY"
thumbnail: "https://i.ytimg.com/vi/P8hjiB709gY/maxresdefault.jpg"
hosts:
  - 노정석
  - 최승준
chapters:
  - time: "0:00"
    title: "2025년 코딩의 해를 지나 2026년 과학의 해로"
  - time: "1:32"
    title: "GPT-5.2와 함께하는 과학과 수학의 발전"
  - time: "3:47"
    title: "AI, 실험실의 속도를 바꾸다: 로봇과 결합한 생물학 연구"
  - time: "8:14"
    title: "수학 난제 해결: AI와 인간의 협업 (Terence Tao 사례)"
  - time: "14:18"
    title: "미국의 새로운 도전: Genesis Mission"
  - time: "17:14"
    title: "Google DeepMind CEO, Demis Hassabis 인터뷰 분석"
  - time: "19:02"
    title: "AI와 에너지: 핵융합의 미래"
  - time: "20:37"
    title: "데이터 고갈의 끝? AI의 자기 학습과 진화"
  - time: "26:33"
    title: "세상을 시뮬레이션하다: World Model의 잠재력"
  - time: "30:28"
    title: "AI는 버블인가? 산업혁명과 비교"
  - time: "38:05"
    title: "AI의 한계는 어디까지인가?"
  - time: "42:52"
    title: "Andrej Karpathy의 2025년 AI 연말 결산"
  - time: "45:54"
    title: "NVIDIA Nemotron과 하이브리드 아키텍처의 미래"
  - time: "54:40"
    title: "샤오미(Xiaomi) 등 최신 AI 모델 동향"
  - time: "56:31"
    title: "마무리 및 다음 에피소드 예고"
lang: "ko"
alternateSlug: null
---

## 2025년 코딩의 해를 지나 2026년 과학의 해로    *00:00*

**노정석**
녹화를 하고 있는 오늘은 2025년 12월 21일 일요일 아침입니다. 네, 2025년이 이제 저물어 가고 있는데요.
2025년에 가장 큰 사건을 꼽으라면 아무래도 Claude Code 출시로 시작된 코딩의 해였을 겁니다.
2026년은 코딩은 이미 끝난 일이고 이제 과학이 또 끝나는 그런 한 해가 될 것이다, AI에 의해서.
이런 이야기들이 이제 2025년을 정리하고 2026년을 전망하는 그러한 세션들이 많이 선보이고 있는데요. 오늘 승준님과 함께 그 이야기들을 한번 훑어보도록 하겠습니다.

<span class="paragraph-timestamp" data-ts="00:40">00:40</span> **최승준** 예, 2026년에 대한 전망들. 그러니까 2025년이 아직 한 10일 남았네요. 오늘 21일이니까요.

<span class="paragraph-timestamp" data-ts="00:45">00:45</span> **노정석** 네, 열흘 남았습니다. 정확히.

<span class="paragraph-timestamp" data-ts="00:49">00:49</span> **최승준** 예, 그런데 2026년이 벌써 새어 들어오고 있다는 느낌을 받게 되는 요즘인데요. 그래서 요즘 나왔던 그 타임라인들의 소식들을 한번 모아봤는데 저희가 그 이전에 이야기에서 OpenAI 팟캐스트, AI와 과학의 미래, 그리고 Google DeepMind의 다큐멘터리 The Thinking Game, 그다음에 Google DeepMind의 공동 창업자인 Shane Legg의 이야기 같은 것들을 좀 소개해 드렸었잖아요. 그래서 지금 계속 맥락을 잡아가고 있습니다.

과학에 대한 어떤 예고편들을 말씀드렸었는데요. 최근 10일 동안 관련 뉴스와 증거, 징후들이 진하게 나오고 있습니다. 그래서 OpenAI에서는 'GPT-5.2를 통해 과학과 수학 발전시키기'라는 블로그 포스팅을 12월 11일, 약 10일 전에 했었네요. 한글로 요새는 블로그들을 내놓더라고요. 그래서 이게 읽기 편하게 되어 있습니다.

## GPT-5.2와 함께하는 과학과 수학의 발전    *01:32*

<span class="paragraph-timestamp" data-ts="01:49">01:49</span> **최승준** 아, 제가 여기 링크를 까먹었는데 Frontier Science라는 벤치마크가 또 아마 생겼을 거예요. 결국에는 그 벤치마크가 만들어지면 성능이 올라가는 약간 아이러니한 상황이 계속 벌어지고 있는데 그런 거에 관련된 소식이 있었고
여기 그 GPT-5.2가 그 위에 블로그에 나와 있는 어떤 사례 부분이 사실은 좀 의미심장한 부분이 있었는데 이게 내용이 좀 어렵긴 합니다.
그래서 지금 여기 COLT라고 Conference on Learning Theory 쪽에서 공개한 문제를 어떻게 풀었는가에 대한 내용인데, GPT-5.2 Pro에게 풀어보라고 요청했고 그다음에 전문가들이 검토와 검증을 통해서 증명을 해낸 사례입니다.

그래서 지금 전 과정에서 인간의 역할은 수학적 발판을 제공하는 것이 아니라 검증과 명확한 글쓰기에 집중하는 데 머물렀다. 그래서 모델이 그것을 해내는 쪽으로 가고 있다. 그리고 이 다루는 문제 자체가 약간 함의하는 바가 있어요. 이런 거를 잘하는 쪽에 관련된 뭔가였거든요.
근데 제 개인적인 감상은 이제부터 올해 코딩 뉴스까지는 내가 좀 따라갈 수 있었는데 2026년의 과학 뉴스는 읽어도 잘 모르겠다라는 뭐 그런 약간 느낌적인 느낌을 받고 있습니다.

<span class="paragraph-timestamp" data-ts="03:08">03:08</span> **노정석** 맞습니다. 사실 수학이나 화학이나 물리가 저희 고등학교나 대학교 때 배운 이런 수준들을 좀 뛰어넘는 그런 깊은 내용들이 많아서
저희가 그쪽에 domain knowledge가 사실 코딩보다는 현저히 부족하기 때문에 이제 들어가서 이게 어떤 내용이다라는 걸 다 보는 것까지는 좀 어렵긴 합니다만
그래도 전반적인 상식 수준에서 이게 무엇이다라는 거는 잘 기술이 되니까 또 한번 보다 보면 또 얻는 게 있을 것 같습니다.

<span class="paragraph-timestamp" data-ts="03:33">03:33</span> **최승준** 그리고 또 AI를 활용해서, AI를 지렛대로 내용들을 읽으면 또 노력하면 어느 정도는 캐치할 수 있긴 한데 이제 정말 체화되는 느낌은 아닐 수 있겠다라는 걱정이 생기더라고요.

## AI, 실험실의 속도를 바꾸다: 로봇과 결합한 생물학 연구    *03:47*

<span class="paragraph-timestamp" data-ts="03:49">03:49</span> **최승준** 그리고 이어서 이게 며칠이었죠. 12월 16일, 그래서 실험실 환경에서 생물학 연구의 속도를 높이는 AI의 역량 평가. 분자 클로닝 프로토콜의 효율을 79배 높이는 데 GPT-5가 쓰였다고 해요.
그런데 여기에서 그냥 그림만 훑어봤을 때 흥미로운 부분은 이렇게 실험, 그러니까 실험실하고 연결된 부분이 좀 의미심장한 것 같아요.
그래서 그냥 시뮬레이션으로만 되는 게 아니라 여기 이제 이미지가 후반부에 나오는데 로봇 시스템으로 이런 것들을 돌려서 실제로 실험하는 것과 데이터를 얻는 것에 어떤 피드백 루프를 만들어내는 것에 성공한 게 아닌가 싶습니다.
로봇이 수행하는 것과 인간이 수행한 것을 비교하는 이런 것들이 나오고 있습니다.

<span class="paragraph-timestamp" data-ts="04:34">04:34</span> **노정석** 이게 왼쪽에 단위가 뭔지는 제가 정확히는 못 봤는데

<span class="paragraph-timestamp" data-ts="04:39">04:39</span> **최승준** 저도 이거를 제대로 보지 않았습니다.

<span class="paragraph-timestamp" data-ts="04:41">04:41</span> **노정석** 사람이 한 것보다 약 2.5배 정도 빠르다 정도네요.

<span class="paragraph-timestamp" data-ts="04:49">04:49</span> **최승준** 그래서 인간이 수행한 것에 비해 더 빠르게 했다, 그리고 성능은 유사하게 나타났다는 거죠.

<span class="paragraph-timestamp" data-ts="04:56">04:56</span> **노정석** 야, 이게 정말 발전 속도가 너무너무 빨라요. 저희가 pre-train과 RLHF 얘기하던 게 사실은 2024년 딱 8월까지고 이게 전부 GPT-5 이후로 시작된 건데 Thinking 모델이 나온 이후에 그게 도대체 어떻게 만들어지냐. 그리고 2025년 1월이죠. R1에 대한 논문이 나오고 Thinking 로직이 이렇게 구성돼 있다. GRPO가 나온 게 그 이후로는 그냥 verifiable reward를 만들 수만 있다면 이건 그냥 모델이 풀 수 있는 게임이다라는 그 믿음이 좀 지배한 것 같고 그래서 코딩이나 수학이라든지 논리가 지배하는 부분, 그런 부분들은 거의 정복이 돼 왔던 것 같고 이제 이게 넘어갔네요, 과학의 영역으로.

<span class="paragraph-timestamp" data-ts="05:40">05:40</span> **최승준** 저희가 저번에 다뤘던 것 중에 Period Labs도 초전도체 관련된 건데 furnace 있고, 그러니까 가마 있고 그런 거 굽고 실험하고 하는 것들을 할 수 있는 환경 자체를 만드는 쪽이었는데 약간 비슷한 느낌이 있죠.
그리고 이게 엔지니어들이 모델로 할 수 있는 것들을 발견한 게 2024년, 2025년에 있었다면 수학자나 과학자들이 이제는 '우리 domain에서 작동하네'라는 것을

<span class="paragraph-timestamp" data-ts="06:06">06:06</span> **노정석** 그리고 많은 과학자들이 얘기하는 게 아까 보여주신 인간이 직접 하는 그런 실험실 환경, 실제로 이렇게 막 물이 왔다 갔다 하고 비커에서 이런 것들을 옮기고 저런 것들을 옮기고 하는 실험 환경을 저희가 wet lab이라고 그러잖아요. 축축한 랩이라고 하는데
그런 부분이 사실은 완전한 병목이었는데 그 부분도 AI가 어느 정도는 후보가 되는 물질들이라든지 방법론들을 최대한 논리로 가려내고
대신 그게 맞냐, 안 맞냐라는 최종적인 reward signal은 직접적으로 실험을 해서 이제 그 실험 환경도 또 로봇으로 이제 막 automation되고 있는 거고요. 네, 그래서 이제 그런 랩들이 2026년에 많이 생겨날 거다,
verifiable reward를 각각의 vertical에서 화학이 됐건 생물이 되었건 생물이나 화학도 sector들이 굉장히 많으니까 그런 것들이 생겨나는 해가 될 거라는 예측들이 많이 보이고 있는 것 같습니다.

**최승준**

제가 여기에 또 얘기를 들으니까 떠오르는데 Google DeepMind 팟캐스트에서 그 Gemini 3가 붙은 팔 로봇이나 휴머노이드형 로봇을 보면 최근에 중국에서 대두되고 있는 그런 fancy한 로봇에 비해서는 덜 fancy하지만 실제로 실험실에 쓸 수 있는 그런 종류의 로봇들을 이번에 많이 소개를 했었거든요. 한 2주 정도 전에.
그래서 이게 연결되는 얘기인 것 같습니다. 그래서 인간의 병목이 있었던 실제로 비커를 다루고 한다거나 재료를 다루고 한다거나 그런 것들에서도 로봇에 의해
그리고 특히나 그냥 로봇이 아니라 reasoning을 갖춘 로봇들이 이제 실험실에 투입되는 상황 같은 것을 보게 될 것 같아요.

<span class="paragraph-timestamp" data-ts="07:44">07:44</span> **노정석** Tesla 자율 주행도 Elon Musk가 지금은 LLM으로 치면 그냥 instruct 모델이거든요. 그런데 거기에 reasoning을 도입하겠다고 얘기하고 있거든요.
네, 그래서 차가 교착 상태에 있거나 이런 상황이 되면 지금은 그냥 모델을 가지고 본능적으로 뒤로 갔다 하면서 얼버무리는데
이제 reasoning이 도입되면 전략을 짜고 임하게 될 것 같아요.

<span class="paragraph-timestamp" data-ts="08:10">08:10</span> **최승준** 그런 일들이 이제 동시다발적으로 보여지고 있고 진행될 예정인 건데요.

## 수학 난제 해결: AI와 인간의 협업 (Terence Tao 사례)    *08:14*

<span class="paragraph-timestamp" data-ts="08:17">08:17</span> **최승준** 수학 쪽에서는 아주 흥미로운 사건이 있었어요. 그래서 이게 Terence Tao의 블로그를 번역을 한 내용이거든요.
그래서 Erdős라고 유명한 수학자가 있는데 그분이 제안했던 문제를 푸는 것을 이게 여기에 길게 나와 있긴 합니다만 제가 수학 공식들은 다 수식을 말로 풀어서 하도록 부탁을 했었어요. 수학 공식이 나오면 저도 너무 어려워해서요.

그런데 TLDR로 핵심을 뽑으면 집단 지성을 활용한 부분이 있어요. 온라인 협업, 그래서 연구자들이 Erdős problems 사이트를 포럼에서 아이디어를 교환하고 AI 도구들이 등장하는데 자동 정리 증명인 Aristotle, 그다음에 Google DeepMind의 AlphaEvolve, 이거를 누구나 쓸 수는 없는 상황으로 알고 있는데 Terence Tao는 이제 access를 받아서 사용하고 있나 보더라고요.

그래서 그 AlphaEvolve를 Terence Tao가 쓴 내용이 있고 그다음에 다른 사람들이 deep research를 돌려서 문헌을, 그러니까 사람은 연결시키지 못하는 거나 찾아내는 것까지 문헌 검색을 하는 것들을 통틀어서 문제를 푸는, 그래서 이게 되게 중층적이고 다양한 단위들, 인간과 AI가 협업해서 이걸 해낸 이야기거든요.
상당히 재미있습니다.

그래서 그거를 1975년에 던져진 질문을 어떻게 풀었는지 온라인에서 협업이 일어나고 그거를 어떤 수학자가 AI 도구를 활용해서 어떤 힌트를 얻고 그거를 보다 보니까 Terence Tao가 '어, 이거는 AlphaEvolve가 할 수 있는 과제네' 하고서는 그걸 했더니 뭔가 또 인간이 아이디어를 얻고 그래서 최종 해결까지.
저도 이거를 꼼꼼하게 다 이해하지는 못했고요. 그냥 흐름만 살펴본 건데요.
이게 결론이 '협업이 가능한 상태다.' 그래서 이거 이렇게 하고서는 또 Lean 같은 증명 보조 도구와 연결되는 부분 같은 것도 있긴 했었는데 어쨌든 수학적인 문제들이 풀리고 있다는 얘기죠.
그런데 Terence Tao와 그 주변의 얘기뿐만이 아니라 다른 곳에서도 반복해서 요새 나오고 있어요. Sébastien Bubeck이 OpenAI에 있는데, 수학자죠.
그래서 그분이 리트윗을 많이 한 건데 지금 여기저기 수학자들이 GPT-5로... 무슨 얘기일까요? 곡선의 moduli 공간에서의 교차 수에 관한 자신의 미해결 문제를 해결했다. 수학이라는 건 알겠죠.
그래서 수학의 어떤 좁은 domain에서의 문제를 GPT-5를 통해서 해결했다.
그리고 지금 여기가 흥미로운 표현인데 이거는 제가 나중에 있는 얘기를 끌어서 올린 건데요. 낮은 low-hanging fruit이 수학에 많다. AI를 활용해서 할 수 있는.

<span class="paragraph-timestamp" data-ts="11:07">11:07</span> **노정석** 난이도가 있는 domain에 오히려 낮은 low-hanging fruit들이 상당히 있는 것 같다는 얘기를 하는 거죠. 네, 근데 이거는 저희한테도 함의는 있습니다. 이게 저희가 business domain도 아직 안 들어간 domain들이 굉장히 많기 때문에 그 안에 개별 개별도 여전히 좋은 그런 과실들이 많이 있을 거라고 저도 그렇게 생각합니다.

<span class="paragraph-timestamp" data-ts="11:30">11:30</span> **최승준** 여기서도 또 COLT, 아까 그 Conference on Learning Theory에서 나왔던 또 다른 문제인 것 같은데요. 그래서 GPT-5.2가 이거를 해결했다.
그래서 이때 증명한 얘기, Lean이랑 연결한 얘기, 그래서 prompt까지 공개를 해서 어떤 수학자분이 그 과정들을 소개한 거를 번역한 거예요.
그런데 그거 말고도 계속 보이거든요. Sébastien Bubeck이 리트윗해서 Sébastien Bubeck의 timeline에 들어가면 최근에 수학이나 과학 쪽에서 있었던 그런 모델을 지렛대로 사용한 이야기들이 계속 나오고 있습니다.
이게 수학 증명의 현재인 것 같다. 작년에 이러지 않았거든요. 작년에는 이런 소리가 별로 없었는데.

<span class="paragraph-timestamp" data-ts="12:17">12:17</span> **노정석** 네, 이게 저희가 농담 삼아 지구에 존재하는 모든 똑똑한 사람들은 전부 AI에 붙어 있다고 보면 된다고들 얘기하거든요. 그리고 수학자, 물리학자 등이 사실은 AI가 아직은 아니라고 얘기하는 특히 의사나 변호사들도 포함해서 그 전문가 계층의 분들이 그런 얘기를 많이 했는데 이제 그분들이 정말 다 AI와 함께 일하는 게 기본이 된 것 같아요. 그러다 보니까

<span class="paragraph-timestamp" data-ts="12:46">12:46</span> **최승준** 그렇죠. 그렇죠. 도망자연합에서 깜짝 놀란 게 의료 쪽에서 오신 분들이 많았어요.
그래서 하여튼 방금 정석님 말씀하신 것처럼 2025년 초반에 OpenAI 팟캐스트 에피소드에서도 블랙홀 연구하시는 과학자가 2025년 초만 해도
'나는 약간 부정적인 시각이었는데 뭐가 가능한지를 보고서는 딸깍했잖아요.' 바로 그냥 뛰어드는 상황.
그래서 지금 많은 수학자, 과학자, 이 분야에 있는 분들이 되기 시작했다. '나도 참여한다' 이런 느낌인 거죠.

<span class="paragraph-timestamp" data-ts="13:24">13:24</span> **노정석** 맞습니다. 저희 유튜브에 어떤 구독자분이 댓글을 남겨주신 것도 있는데 저희가 여기에서 '와, 이 모델 정말 좋아'라고 하는 건 비싼 모델들이거든요.

GPT-5.2 Pro 같은 모델들을 가지고 또 prompting도 정교하게 잘했을 때 나오는 결과들인데 그냥 무료 모델에 abstract한 prompt 한 줄 정도를 던지고 나오는 답변이 부실한 것에 '야, AI는 아직 아니야'라는 그런 판단을 내리는 것들을 많이 목격하고 아쉽다는 말씀을 해주신 게 기억나는데
prompting을 잘하는 기법을 배우는 것도 여전히 매우 유효하다.

**최승준**
네, 전문가들이 좋은 질문 던지고 계속 지난하게 왔다 갔다 back and forth로 prompting하고 집단 지성을 발휘하고 그러면서 풀리는 거지 이렇게 정말 딸깍 하면서 풀리는 거는 아직 오늘의 모습은 아니긴 합니다.
그리고 또 강력한 모델, 아까 말씀하셨듯이 현존하는 가장 flagship의 첨병에 있는 모델들을 사용하는 부분들도 물론 있고요.

## 미국의 새로운 도전: Genesis Mission    *14:18*

<span class="paragraph-timestamp" data-ts="14:18">14:18</span> **노정석** 그런데 이런 게 지금 국방부가, 그러니까 미국 국방부가 그러니까 White House, 그러니까 백악관이 그냥 명령을 때렸어요. 그래서 창세기 미션이라고 해야 되나, Genesis Mission을 발표한다.
그래서 제가 지금 여기다 번역을 쭉 했는데요. Google DeepMind, Anthropic, 그다음에 OpenAI까지가 다 화답을 한, '같이 한다'라는 상태고요.

Genesis Mission이, 쭉 한번 훑어보면 이게 결국에는 국가 과학기술 도전 과제, 예전에 아폴로 프로젝트라든가 러시아의 스푸트니크호였나요? 그 인공위성 발사하고서는 60년대에 미국 과학계가 엄청 긴장해서 총력을 기울인 게 결국에는 컴퓨터의 발전과도 맞물려 돌아갔었잖아요.
그래서 그런 것과 비슷한 느낌도 드는데 어쨌든 범정부적으로 이거를 진행하겠다.
Google DeepMind도 이렇게 Genesis 임무를 지원해서 혁신과 과학적 발견을 가속화하기 위한 '국가적 사명', 뭐 이렇게 해서 블로그 포스팅을 했고요.

그래서 미국 과학자들에게 첨단 AI 도구를 제공하겠다. 그래서 아까 Tao가 AlphaEvolve를 쓸 수 있는 것처럼 AlphaEvolve, AlphaGenome, WeatherNext, 이거는 아마 super computing 쪽이었던 것 같은데 그런 것들에 접근할 수 있게 열어주는 작업 같은 걸 하겠다.
그래서 이런 것들이 그동안 있어 왔다.
그래서 이렇게 참여에 대한 것들을 해서 직면한 과제들, 에너지에서 질병, 안보에 이르기까지 이런 것들을 하는 방향이다.
그리고 Anthropic 쪽은 간략히 이 정도 언급을 했고요. '참여한다.'

<span class="paragraph-timestamp" data-ts="16:01">16:01</span> **노정석** Manhattan Project예요. 이게 중국과 미국 사이에 누가 더 초지능에 먼저 도달하느냐, 이 부분이 안보에 직결되는 내용이다 보니까 이제 국가 단위의 프로젝트까지 결성됐고.

<span class="paragraph-timestamp" data-ts="16:16">16:16</span> **최승준** 맞습니다. 아폴로 전에 Manhattan이 있었죠. 지금 Jared Kaplan도 물리학자잖아요.
이분이 Johns Hopkins에 있었는데 사실 과학에 관련된 맥락으로 OpenAI와 Google DeepMind가 막 이렇게 강하게 메시지를 내고 있긴 하지만 공동 창립자들이 과학자인 거는 Anthropic이 제일 많거든요.
그래서 물리학자들이 많이 있고 물리학자들 영입을 많이 했어서 여기서도 코딩 모델에 전력을 기울이곤 있지만 또 다른 생각이 있을지도 모르겠다는 추측 같은 걸 해봤습니다.
그리고 OpenAI는 에너지부와 협력을 심화한다고 해서 좀 더 자세히 다뤘고요. 내용들은 다 비슷해요.

<span class="paragraph-timestamp" data-ts="16:57">16:57</span> **노정석** 부러운 얘기네요. 부러운 얘기.

<span class="paragraph-timestamp" data-ts="17:02">17:02</span> **최승준** 그래서 이런 것들이 맥락이 현재 미국 국가적인 미션이 있고 증거들이 나오고 있고 그래서 다시 처음에 Demis Hassabis의 인터뷰로 돌아가면 탭 정리를 하겠습니다. 이게 정석님도 보시긴 했다고 하셨죠?

## Google DeepMind CEO, Demis Hassabis 인터뷰 분석    *17:14*

<span class="paragraph-timestamp" data-ts="17:18">17:18</span> **노정석** 네, 봤습니다. Hannah Fry 이 교수님도 하도 많이 봐서 이제 익숙해요. 네, 이번 시즌 마무리 편인 것 같아요.

<span class="paragraph-timestamp" data-ts="17:26">17:26</span> **최승준** 그렇죠. 올해의 마지막 그 Google DeepMind 팟캐스트 편인데요. 내용은 역시 재미있었는데 문제는 너무 짧은 시간에 제가 이런 걸 많이 보다 보니까 금방 휘발돼요. 그래서 한번 저희가 대화를 나누면서 기억을 한번 인출해 보시죠.

<span class="paragraph-timestamp" data-ts="17:42">17:42</span> **노정석** 어느 정도는 오래 있었던 일종의 시각 변화, sentiment의 변화를 가장 잘 요약하고 있는 대화 같아요. 네, 올해 초만 하더라도 AGI가 되냐 안 되냐, 언제 될 것 같냐, 이런 예측들이었다면
후반부로 오면서 이건 되는 게임이고 언제 되느냐로 바뀌었거든요.
이제 25년이 끝나는 이 시점에 제일 큰 점이 있다면 이건 무조건 되는 거다라는 이야기들을 다 마무리하고 있다.

<span class="paragraph-timestamp" data-ts="18:12">18:12</span> **최승준** 그래서 Demis Hassabis도 원래 되게 신중한 사람이지만 원래 그러면서 Google DeepMind의 최초의 미션은 AGI에 다가가는 거였잖아요. 그래서 어떻게 보면 가장 이 일을 오래 한 팀의 수장이죠. 지금 보면 Demis Hassabis가 이제는 이런 말을 한다고 할 정도로 급진적인 발언들을 해요.

<span class="paragraph-timestamp" data-ts="18:32">18:32</span> **노정석** 항상 조심스럽게 얘기하고 누가 된다고 하더라도 그건 좀 지켜봐야 합니다라고 얘기했었어요.

<span class="paragraph-timestamp" data-ts="18:38">18:38</span> **최승준** 그렇죠. 그래서 과학적인 방법이 제일 중요하다. 그게 2024년에 구글하고 Google DeepMind가 합쳐지기 전에 발휘했던 메시지가 우리가 좀 신중하게 가면서 해야지 하입을 따라가면 안 된다, 그런 이야기했던 분인데

<span class="paragraph-timestamp" data-ts="18:56">18:56</span> **노정석** 포인트들을 한번 살펴보시죠. Demis가 했었던 이야기들

## AI와 에너지: 핵융합의 미래    *19:02*

<span class="paragraph-timestamp" data-ts="19:02">19:02</span> **최승준** 처음에 시작이 되게 인상적인 게 에너지 문제가 풀린다는 것에 대한 가정 같은 걸 얘기를 했었어요. 그래서 핵융합이 풀리면 SMR이라고 소형 원자로도 물론 있긴 합니다만 핵융합이 풀린다면 어떻게 될까 그러니까 풍요의 시대에 대한 상을 잡으면서 시작을 했거든요.
Hannah Fry와의 대화가 그래서 그 얘기는 뭔가 에너지 관련된 것도 하고 있나 그런 얘기인데 실제로 하고 있대요. Commonwealth Fusion하고 깊은 파트너십을 발표했다고 합니다.
당연하겠지만 이게 풀리고 풀린다는 거는 결국에는 에너지는 저희가 계속 얘기했듯이 에너지와 지능이, 와트와 지능이 치환된다 그런 얘기했었잖아요.

<span class="paragraph-timestamp" data-ts="19:39">19:39</span> **노정석** 맞습니다. 저희가 이제 NVIDIA GPU 몇 장 이런 표현을 안 하잖아요. 이건 신정규 대표님이 말씀해 주신 건데 전력량으로 계산량을 치환해서 얘기하는 게 새로운 단위가 됐더라고요. 그래서 기가와트, 기가와트급이 하나의 기준이 된 것 같아요.

<span class="paragraph-timestamp" data-ts="19:58">19:58</span> **최승준** 그러니까요. 그래서 지금 약간 SF 같은 얘기인데 에너지 문제를 해결하면 기존의 많은 문제들이 사라지죠. 이러면서 초반부를 잡았거든요.

<span class="paragraph-timestamp" data-ts="20:06">20:06</span> **노정석** 네, 다 치환할 수 있죠.

<span class="paragraph-timestamp" data-ts="20:08">20:08</span> **최승준** 그래서 에너지가 싸고 재생 가능하고 깨끗하다면 24시간 365일 생산하는 에너지가 있다면 그게 또 결국에는 AI에 쓰일 건데 그런 약간 상상 같은 걸 하게 되는 얘기가 초반부에 있었고요. 그다음에 역시 아직은 들쭉날쭉하다. 한 50% 정도만 온 것 같다는 얘기를 했어요. 자명한 문제들이 있는 건 확실하고 들쭉날쭉하긴 한데 그게 못 푸는 문제는 아닐 것이라는 이야기를 했습니다.

## 데이터 고갈의 끝? AI의 자기 학습과 진화    *20:37*

<span class="paragraph-timestamp" data-ts="20:41">20:41</span> **최승준** 데이터 고갈에 대한 얘기들이 아마 뒤에 나왔던 것 같은데요. 그거 아니다, 얼마든지 생성할 수 있고 그다음에 인간 의존적인 데이터에서 벗어나는 체제로 가는 것도 이제, 이 부분이죠. 오늘날 빠져 있는 거는 온라인 학습, 그러니까 continual learning인데 현재는 빠져 있지만 행간에서는 그런 것들을 다루고 있다.

저번 Shane Legg 편에서도 그렇고 그런 얘기들을 읽을 수 있었습니다. 그다음에 이 부분이 이제 Google DeepMind의 기존 태도를 Hannah Fry가 물어봤어요. 더 오랫동안 실험실 안에 가뒀어야 했는가 그런데 Demis도 Google DeepMind를 합친 다음에는 제품을 내는 것 쪽에 굉장히 많이 참여를 하다 보니까 그것의 장점도 있다. 그래서 어떤 부분을 잃고 어떤 부분을 얻었다.

만약에 실험실에 좀 더 가뒀으면 암을 해결했을 수도 있었을 텐데 그런 얘기를 하기도 했거든요. AlphaFold나 이런 거 만드는 쪽으로 좀 더 집중했으면 그런 문제들을 해결했을 수도 있는데 실제로 제품을 내면서 하다 보니까 또 얻는 많은 것, 그런 가능성들이 있었다 같은 얘기들을 했습니다.
그렇죠. 그리고서는 미친 경쟁 상황을 만들어 냈다. 그래서 그런 상황에서는 엄격한 과학을 하기는 어렵지만 그 균형을 맞추려고 하고 있다 이 부분도 재미있었습니다.
또한 흥미롭게도 일반 대중이 실제로 최첨단에서 불과 몇 달 뒤처져 있다 그래서 누구나 AI가 뭔지 느낄 수 있는 기회를 갖게 됐다. 그리고 정부들도 AGI로 향하는 것을 더 잘 이해하게 됐다는 얘기를 했습니다.

<span class="paragraph-timestamp" data-ts="22:18">22:18</span> **노정석** 얼마 전 저녁 식사 자리에서 신정규 대표님이랑 우연히 또 만났는데 그 얘기하시더라고요. 제가 Chester 님이 얘기하는 Elon Musk나 Sergey Brin이 우리보다 몇 개월 더 frontier를 보고 있을 거라는 건 아마 틀렸을 거다. 많이 잡아줘도 한 달 정도 빨리 보고 있을 걸요 라고
이 frontier와 오픈되는 갭이 생각보다 굉장히 작다. 아마 그거는 중국과 미국의 경쟁, OpenAI와 구글의 경쟁 이런 것들이 영향을 미쳤겠지만
거꾸로 저희 같은 일반인 입장, 동호인 입장 자본이 없어서 training에 참여하지 못하는 이런 입장에서 보면 행복한 세상이죠. 끼워주는 거니까

<span class="paragraph-timestamp" data-ts="23:04">23:04</span> **최승준** 물론 한 달에 200불은커녕 한 달에 2, 3만 원도 약간 비용이 들기 때문에 모두에게 또 되는 건 아닐 수 있겠습니다만 지금 문턱은 어마어마하게 낮아져 있는 상태는 맞죠?

<span class="paragraph-timestamp" data-ts="23:12">23:12</span> **노정석** 그리고 200불 요금제도 저희 한 봄, 여름 올 때까지만 하더라도 대부분 사람이 안 쓰던 영역이었어요. 근데 지금은 200불 쓰는 분 제가 굉장히 자주 보거든요. 그러니까 그만큼 돈값 이상을 한다는 얘기죠.

<span class="paragraph-timestamp" data-ts="23:23">23:23</span> **최승준** 근데 문제는 인식의 지평은 또 들쭉날쭉함이 있긴 하죠.

<span class="paragraph-timestamp" data-ts="23:31">23:31</span> **노정석** gap은 어마어마하게 벌어져 있습니다. 이 AI의 frontier를 따라가는 사람과 그것들을 어떻게든 그쪽에 가보겠다고 하는 저희가 도망자라고 define한 그런 영역과 그러지 않기로 한 사람들은 gap은 너무 벌어져 있습니다.

<span class="paragraph-timestamp" data-ts="23:50">23:50</span> **최승준** 하여튼 그런 시절인데 그다음에 또 얘기한 것이 scaling에 대한 얘기였었어요.
그래서 여기서도 합성 데이터 등 어쨌든 우리가 scaling 안 된다고 한 적 없다.
그래서 지금 그게 약간 이 부분이 이 문단 부분이 재밌는데 항상 이렇게 치고 올라가지 않더라도 늘 얻을 수 있는 부분이 있었다. 0이나 1이 아니라는 거죠. 그 사이에 어떤 부분이 있기 때문에 우리는 계속 scaling 되고 있었다는 뉘앙스로 읽었습니다.

<span class="paragraph-timestamp" data-ts="24:23">24:23</span> **노정석** 이 부분에 대해서 숫자적인 감을 좀 잡아보면 제가 Nemotron paper를 읽으면서 그런 게 느껴졌는데 보통 이 frontier 모델을 학습시키는 데 사용되는 토큰의 수가 20조가 넘거든요. 27조 정도가 전체 사용된 토큰인데
재밌는 거는 그중에 수학, 과학이라든지 아니면 핵심 논리에 해당하는 부분들은 Qwen 30B이나 이런 거 저희가 예전 paper에서 봤던 식으로 이 pre-training dataset도 계속 품질을 높이고 있거든요.
근데 그렇게 높인 high-quality dataset은 이만큼이다라고 얘기하는 그런 양이 아직 1조가 안 돼요. 그러니까 한 5,000억 정도 되거든요. 5,000억 정도 되는 그런 숫자라서
아직 정제되지 않은 raw한 pre-training data들도 끊임없이 뒤에서 계속 품질이 좋아지고 다시 쓰여지고 있고 이러고 있기 때문에 여전히 그런 부분에서도 scale이 계속 지배하고 있는 거라고 보고 있습니다.
RLHF와는 또 완전 다른 그냥 pre-train 영역인데 거기도 여전히 dataset의 품질이 계속 높아지면 높아지는 만큼 단위 에너지당 수율은 좋아지는 거니까 여기도 여전히 upside가 크게 있다.

<span class="paragraph-timestamp" data-ts="25:36">25:36</span> **최승준** 그리고 bootstrapping이 되고 있는 거라서 시스템이 충분히 좋아지면 자체 데이터를 생성한다. 코딩이나 수학처럼 답을, 답을 어떤 의미에서 검증할 수 있는 도메인은 무제한 데이터를 생산할 수 있다 그런 얘기를 했습니다, Hassabis가.

<span class="paragraph-timestamp" data-ts="25:53">25:53</span> **노정석** 그래서 scaling의 한계다, wall이다 이런 이야기도 25년이 끝날 때는 희미해지고 있다.

<span class="paragraph-timestamp" data-ts="25:59">25:59</span> **최승준** 50%는 scaling에, 50%는 혁신에 쓴다. 그래서 기존 regime에서도 scaling 하는 걸 노력하고 있고 또 그 외의 방법들에서도 혁신에 노력을 하고 있다, 그런 얘기했었고 환각 문제는, 환각은 여전히 있긴 하지만 해결될 가능성이 있을 것이다 여기서 확신, 정확한 얘기를 하지는 않았는데요, 어쨌든 나아지고 있는 쪽으로 얘기를 합니다.
근데 물론 인정은 하긴 했었어요. 여전히 있다.

## 세상을 시뮬레이션하다: World Model의 잠재력    *26:33*

<span class="paragraph-timestamp" data-ts="26:33">26:33</span> **최승준** 그리고 world model에 대한 것을 했거든요. Genie나 Veo, 그리고 SIMA 같은 걸 했는데 이 부분이 사실 굉장히 SF적이면서도 흥미로운 얘기였어요.

그래서 여기 조금 넘어가면 결국 Demis Hassabis는 그 시작부터가 게임 백그라운드가 있지 않습니까? 그래서 테마파크라든가 유명한 시뮬레이션을 하는 그런 게임들을 개발하는 걸 어린 시절에 했었는데 이게 시뮬레이션이 되면 해결할 수 있는 문제다 같은 걸로 지금 SIMA나 아니면 Genie 같은 것들을 소개해요.
Genie는 환경을 생성하는 거잖아요. 실시간으로 SIMA는 그 환경 안에 들어가서 활동할 수 있는 에이전트거든요.
그래서 Gemini의 추론 능력을 가지고 있는 SIMA 에이전트가 Genie가 만들어내는 환경 안에서 끊임없이 문제를 풀고 있으면 어떻게 될 거냐 이런 얘기를 했거든요.

<span class="paragraph-timestamp" data-ts="27:32">27:32</span> **노정석** 그러면 우리가 정의할 수 없는 그런 문제 공간들, problem space들을 다 search로 풀어내는 게 될 거고 모든 문제를 다 해결할 수 있다는 얘기를 하는 거죠. 무한의 computation만 주어지면

<span class="paragraph-timestamp" data-ts="27:46">27:46</span> **최승준** 그게 이제 8월이었네요. 그래서 Genie가 나와서 이 공간에 들어가서 실제로 navigation 할 수 있고 그런 건데 SIMA는 11월에 나왔거든요.
그래서 그 안에서 이건 실제로 No Man's Sky 같은 게임 안에서 그걸 탐험하는 건데 어떤 게임이든 들어갈 수 있는 에이전트예요.
근데 그 내부적으로 지금 시도하고 있는 게 Genie를 SIMA에 연결해서 즉석에서 세계를 만드는 그런 것들을 하고 있고 제가 지금 논문을 빼먹었는데 그걸 하는 논문도 Google DeepMind에서 공개한 게 있거든요.
그 루프를 만든 거, 정보를 워낙 많이 봐서 가물가물해서 오류가 있을 수도 있습니다만 하여튼 본 것 같아요.

<span class="paragraph-timestamp" data-ts="28:32">28:32</span> **노정석** 그러니까요. 이게 Demis가 하면서 느끼는 게 Demis랑 Elon Musk나 비슷한 얘기를 하는데 Yann LeCun이라든지 아니면 Sutton이 얘기하는 건 약간 old school이다.

사실 모델은 구조가 어떻게 되었건 inductive bias를 최대한 제거하고 모델을 general하게 만들고 거기에 무한의 computation을 넣으면 풀지 못할 문제는 없다는 게 이제 이들의 기본 시각이거든요. 사실 Transformer, 뭐 언어 사이에 attention 계산하는 건데 general한 logic으로 넣고 이미지 넣고 해서 다 써먹고 있잖아요.
그러니까 결국 어느 임계점을 넘으면 다른 형식 시스템이 나와서 걘 다 해결해 준다 라는 이야기를 이들도 하고 있는 거고 예제로 드는 게 Genie나 Veo 예제를 보면서 단순히 학습시킨 것에 불과한데 매우 정교한 물리 엔진을 가지고 있지 않느냐는 이야기를 하죠.

그래서 저도 개인적으로는 AGI, ASI를 위해서 Transformer 아키텍처라든지 이런 형태의 모델은 architecturally 뭔가 제한이 되어 있다는 어떤 old school, Yann LeCun이나 Sutton이나 이런 식의 이야기는 의미 없다고 생각합니다.

**최승준**
비슷한 얘기를 Demis도 하는데 일단 현재 시뮬레이션은 육안 정밀도지 정말 완벽한 정밀도를 가지고 있지는 못하다. 하지만 방향성은 그걸 하려고 하는 거다. 제대로 된 물리학 등급 실험을 견딜 수 있느냐 그런 얘기들을 좀 했었고요.

그래서 이 시뮬레이션에 대한 Demis의 어떤 오래된 생각들을 쭉 얘기하는데 Santa Fe Institute의 어떤 실험 같은 것들도 언급하고 거기서 어떤 경제 구조나 이런 것들이 grid world에서 창발하는 얘기 같은 것도 하고 의식에 대한 얘기도 하고 그러는데 그래서 Demis의 생각은 시뮬레이션된다면 되는 거 아니냐 그런 얘기들을 여기서 한번 짚고 후반부에 또다시 짚긴 합니다.

## AI는 버블인가? 산업혁명과 비교    *30:28*

<span class="paragraph-timestamp" data-ts="30:29">30:29</span> **노정석** 그래서 쭉 한번 넘어가면 이것도 질문이 재미있었어요. Hannah Fry가 단도직입적으로 AI 버블이냐 아니냐, 그래서 버블이 터지면 어떻게 되나 그래서 Demis가 허심탄회하게 인정한 건 지금 버블이 껴 있긴 하다. AI 생태계의 일부는 아마 버블일 거다.
근데 터지는 것에 대해서는 터지면 어떻게 되느냐에 대해서는 직접적인 답변을 하지 않고 Google은, Google DeepMind는 터지더라도 안전하다. 우리가 지금 어떤 것에 hedging이 되어 있고 어떤 기반이 있고 하는 그런 것들을 좀 짚었습니다.
TPU 있고 연구가 어떻게 되어 있고 그런 것들을 하면서 우리는 이 방향이 계속돼도 좋고 안 되더라도 잘할 수 있다 그런 얘기를 약간 자랑하긴 했습니다.

**노정석**
네, 근데 이것도 신정규 대표님이 그때 저녁 식사 자리에서 얘기했던 거고 예전에 저희 팟캐스트에 나와서도 얘기하셨던 건데 이거 너무 과투자 아니냐 이제 남아돌 거라는 이야기를 했었지 않습니까?
컴퓨팅 자원의 끝이라고 했는데 지금 현실의 예제로 이미 얘기하고 있는 게 저희 인터넷 트래픽의 97%가 비디오거든요. YouTube랑 Netflix거든요.
3%만이 텍스트와 이런 다른 데이터를 옮기는 데 쓰이고 있고 이미 토큰 생성 역시 저희가 Claude로 100만 토큰 쓰려면 얼마나 어렵냐 진짜 많이 써도 25만 토큰, 뭐 이렇게 하는데
사실 어디 나노바나나에 이미지 생성 하나만 시켜도 2만 5천이고 비디오 하나 30초 정도 생성시키면 몇십만 토큰 써버리기 때문에 앞으로 이쪽은 더 커질 거라서 이제 겨우 시작에 불과하다.
여기도 역시 대부분의 토큰은 이 멀티미디어, 그러니까 비디오나 이런 콘텐츠에서 나올 거지 텍스트나 코딩, science, logic 이런 것들은 그 안에서 매우 일부분일 거라는 이야기를 하시더라고요.
네, 그래서 makes sense 했습니다.

<span class="paragraph-timestamp" data-ts="32:23">32:23</span> **최승준** 예, 흥미로운 저녁 식사 시간을 보내셨네요.

<span class="paragraph-timestamp" data-ts="32:26">32:26</span> **노정석** 네, 그렇기 때문에 이 반도체 투자 사이클은 사실 과투자 국면 아니냐가 아니라 이제 시작하는 거라고 봐야 된다.
네, 그리고 아직 밖에 소문은 많이 안 나 있는데 이진원 님이라든지 이제 칩 하시는 분들 만날 때마다 하시는 얘기가 뭔가 개발하고 싶은데 RAM을 살 수가 없다 HBM을 사는 것도 아니고 LPDDR을 사는데도 다음 납기가 1년 후다, 2년 후다.
그리고 삼성도 LPDDR 다 팔았고 가격 2배 올렸고, 뭐 이런 얘기하거든요.
그래서 메모리 슈퍼 사이클이 또 시작됐다.
그래서 그 얘기는 뭐냐

<span class="paragraph-timestamp" data-ts="33:05">33:05</span> **최승준** 진원 님 얘기 나왔으니 언제 한번 초청해서 저희도 얘기를 좀

<span class="paragraph-timestamp" data-ts="33:09">33:09</span> **노정석** 저희 반도체 얘기 한번 들어봐야죠.

<span class="paragraph-timestamp" data-ts="33:15">33:15</span> **최승준** 그래서 여기는 echo chamber 쪽은 sycophancy, 뭐죠? 아첨 관련된 그런 얘기인데 일단 넘어가겠습니다.
그래서 이게 AGI에 대한 얘기가 이제 저번에 Shane Legg 편하고 연결돼서 일어나는 그런 것들을 조금 소개한 부분이었고요. 어쨌든 뭔가 emerging을 위한 AGI에 가까워지고 있다.
그래서 지금 proto-AGI의 후보 정도가 지금 그러니까 이런 것들이 Genie, SIMA, 그런 것들이 다 통합이 되면 proto-AGI의 후보 정도가 될 것 같다.
그리고 이 부분도 재미있었습니다. 산업혁명에서 배우는 교훈, 산업혁명에 대해서 최근에 책을 많이 읽었대요. Demis가 그래서 그게 오면 어떤 혼란을 완화하는 측면에서 예전에 그 역사를 다시 공부하고 싶은 그런 부분들을 좀 읽게 됐대요.
그런데 여기서 산업혁명보다 10배 크고 10배 더 빨리 일어날 거다. 한 세기가 아니라 약 10년에 걸쳐 펼쳐질 거다.
산업혁명에 관련된 거의 200년에 걸쳐서 일어났었죠, 제 기억으로는.

<span class="paragraph-timestamp" data-ts="34:25">34:25</span> **노정석** 그러나 저희가 실질적인 걸로 보는 건 한 100년 된 거죠. 1800년대 후반부터 1900년대 후반까지를 보죠.

<span class="paragraph-timestamp" data-ts="34:32">34:32</span> **최승준** 근데 세상이 난리가 났었거든요. 그때도, 근데 지금 10년 안에 일어난다면 난리가 더 난다는 얘기죠, 사실.

<span class="paragraph-timestamp" data-ts="34:38">34:38</span> **노정석** 현실의 이야기로 돌려서 얘기해 보면 그때는 세대를 걸쳐 일어났기 때문에 부모가 실업자가 되면 아이들은 새 직업이 있는 세상에서 살 수 있었는데 지금은 부모와 아이가 동시에 실업자가 되는 세상이라는 얘기거든요.

<span class="paragraph-timestamp" data-ts="34:54">34:54</span> **최승준** 웃으면서 할 말은 아니긴 한데 좀 어이없어서 그렇습니다.

<span class="paragraph-timestamp" data-ts="34:58">34:58</span> **노정석** 네, 웃으면서 할 얘기는 아닌데 맞아요. 근데 결국은 정부 시스템이 저는 훨씬 중요해질 것 같아요. 부가 몇 개의 회사에 극단적으로 몰릴 거고 그럼 거기에서 얻어진 걸 가지고 진짜 보편 소득, basic income이라든지 아니면 보편을 넘어서서 Sam Altman은 막대한 소득이라고 하잖아요. 훨씬 더 많은

<span class="paragraph-timestamp" data-ts="35:20">35:20</span> **최승준** 그렇죠. 그렇죠. 뭐 그런 얘기 basic income이 아닌 걸 얘기하는 사람들도 있죠.

<span class="paragraph-timestamp" data-ts="35:29">35:29</span> **노정석** 26년에 사실 25년에 축적됐던 이런 어떤 생산성 변화가 현실에 올 거라고 다들 예상하시더라고요. 회사에서 대량 해고가 사실 일어날 거다. 26년에 벌써.

<span class="paragraph-timestamp" data-ts="35:40">35:40</span> **최승준** 그래서 사실 그게 다시 에너지 얘기랑 맞물려 돌아가거든요. 에너지 문제가 풀리면 상당 부분 그런 어떤 경제적인 압력이나 개인이 겪어야 되는 어떤 그런 압박을 해소할 수 있는 부분들이 있지 않나. 물론 에너지 문제가 풀려도 여전히 다른 문제들은 얽혀 있긴 할 텐데 하여튼 이게 여러 가지가 같이 맞물려 돌아간다는 느낌을 받습니다.

<span class="paragraph-timestamp" data-ts="36:02">36:02</span> **노정석** 사회적 담론까지는 너무 가지 마시죠.

<span class="paragraph-timestamp" data-ts="36:08">36:08</span> **최승준** 저도 그렇죠. 근데 Demis가 한 얘기라서요. Demis가 이번 편에서 그런 걸 많이 다뤘거든요. 그래서 새로운 경제 시스템, 뭐 그런 얘기도 하고

<span class="paragraph-timestamp" data-ts="36:16">36:16</span> **노정석** 일단 빨리 변화에 적응하는 걸 저희는 지향하고 있으니 빨리 변화에 적응합시다.

<span class="paragraph-timestamp" data-ts="36:23">36:23</span> **최승준** 뭐 post-AGI, 뭐 그런 얘기는 Shane, Shane Legg가 뭐 생각하는 노력을 이끌고 있다고 하는데요. 그래서 어떤 경제학자들하고 정부하고도 그런 맥락에서 얘기를 한다. 그래서 여기서 제가 조금 전에 했던 얘기가 그거네요.
경제학자 친구들에게서 흥미로운 얘기 들었고 더 많은 이 관련 작업이 있었으면 좋겠고 철학적 측면도 있다.
일자리가 변하고 다른 것들도 변하지만 어쩌면 핵융합이 해결됐을 수도 있다. 그래서 풍부한 에너지가 있고 희소성 이후의 세계가 된다 그러면 돈은 어떻게 되나.
모두 더 잘 살지만 목적은 어떻게 되나. 왜냐하면 많은 사람들이 직업에서 목적을 얻고 가족을 부양하는 것에 목적을 얻는데 그건 매우 고귀한 목적이다. 그런데 그게 없어진다면,
그래서 이런 질문들이 일부는 경제적 질문에서 철학적 질문으로 혼합된다. 이런 얘기를 이번 편에서 했습니다.
하여튼 그리고 그런 거에서는 국제적인 협력이 필요하다. 그런데 생각보다 잘 일어나고 있지 않다. 그래서 모두가 주목하게 하려면 어떤 사건 사고가 필요할 거냐. 그랬더니 대부분의 연구소들은 책임감이 있는데 오픈 모델도 있고 하기 때문에 모든 거를 통제할 수는 없다.
그래서 약간 다룰 수 있는 정도의 사건이 일어나면 괜찮은 거 아닌가. 그 rogue AI, rogue, 뭐 이렇게 rogue라는 표현이 약간 그런 위험한 거 하는 쪽이잖아요.

<span class="paragraph-timestamp" data-ts="37:43">37:43</span> **노정석** 네, rogue. 네.

<span class="paragraph-timestamp" data-ts="37:45">37:45</span> **최승준** 예, 그렇죠. 엑스맨에도 Rogue가 있긴 한데 어쨌든 그래서 불량이네요. 불량 국가, 불량 조직 그런 거를 막기는 어렵지만 중간 정도의 것이 일어나면 경고 사격이 될 것이다. 그러면 국제적인 협력이나 표준이 더 잘 만들어지지 않을까. 그런 얘기들을 하기도 했습니다.

## AI의 한계는 어디까지인가?    *38:05*

<span class="paragraph-timestamp" data-ts="38:05">38:05</span> **최승준** 그래서 인간만이 할 수 있는 것이 있을까. 그런데 한계는 없다.

그래서 이 부분이 사실은 저희가 또 정석님이 관심 있는 거랑 많이 연결되는데, Demis도 계산을 믿는 분이더라고요. 그래서 von Neumann 체제에서 Turing machine의 방법으로 추구해서 안 되는 거가 아직까지 증거가 없다. 이 방법으로 계속 밀어붙이겠다, 이런 얘기를 했습니다.

그래서 모든 게 고전 컴퓨터로 복제 가능하다. 그러니까 여기서 하나 프라이가 도전적인 질문을 했는데, 여기 앉아 있고 조명의 따뜻함이 느껴지고 배경에 기계 소리가 들리고 손에 있는 어떤 촉감, 그런 것들이 다 고전 컴퓨터로 복제가 가능하다고 Demis는 말한다고 한 번 더 이렇게 짚어줬고요.
그래서 Demis가 철학자 2명을 얘기를 해요. Kant랑 Spinoza를 얘기를 하는데 굉장히 또 Spinoza를 저도 잘 몰라서 찾아보니까 흥미로운 얘기들이 나오더라고요.
시뮬레이션된 세계가 중요하다. 시뮬레이션할 수 있는 것에 한계가 뭔가요? 시뮬레이션을 할 수 있다면 어떤 의미에서는 이해한 것이다. 그래서 Demis가 무슨 생각을 하고 있는지가 이번 편에 되게 많이 밝혀졌어요.

<span class="paragraph-timestamp" data-ts="39:13">39:13</span> **노정석** 저 위에서 쓴 Isomorphic이란 저 형용사

<span class="paragraph-timestamp" data-ts="39:16">39:16</span> **최승준** Isomorphic, 예. Demis가 대표인 또 다른 회사죠.

<span class="paragraph-timestamp" data-ts="39:24">39:24</span> **노정석** 네, Isomorphic Labs라고 이게 생명공학 신약 개발 회사거든요. 또 Isomorphic이라는 형용사도 괴델, 에셔, 바흐에서도 핵심 형용사거든요.

<span class="paragraph-timestamp" data-ts="39:30">39:30</span> **최승준** 그래요? 그런가요?

<span class="paragraph-timestamp" data-ts="39:37">39:37</span> **노정석** 예, 결국은 모든 게 관계가 지배한다는 거고 남는 건 관계밖에 없다고 그 매질이 무엇이 되든지 간에 그 관계가 일치한다면 그건 똑같은 거라는 거거든요. 동형성의 원리인데

<span class="paragraph-timestamp" data-ts="39:48">39:48</span> **최승준** 그렇게는 생각을 못 해봤는데 저도 한번 다시 봐야겠네요. 그래서 Demis도 이런 얘기를 했는데, 잠을 못 잔대요. 여러 가지 이유로 흥분되기도 하지만 일이 많기도 하고 꿈꿔왔던 걸 하고 있고

<span class="paragraph-timestamp" data-ts="39:59">39:59</span> **노정석** 많은 방면에서 과학의 절대적 최전선에 서 있다. 예전에 Noam Brown도 그 얘기했었죠. 아침에 일어나서 frontier가 얼마나 진보했는지 보는 거는 참 자기에게 주어진 어떤 privilege라는 표현을 했네요. 특권, 예.

<span class="paragraph-timestamp" data-ts="40:14">40:14</span> **최승준** 맞아요. 예, 그런 얘기를 했었죠.

<span class="paragraph-timestamp" data-ts="40:16">40:16</span> **노정석** 부럽습니다.

**최승준**
시간이 한참 지났기 때문에 그냥 빠르게 넘어가면 예, 뭐 이렇게 AI 리더들 사이의 관계 그리고 우려되는 거 그다음에 이게 결국에는 우려되는 거, 기대하는 거
그리고 여기서 재미있는 부분이 Demis는 AGI를 안전하게 넘기도록 세계를 돕는 거가 자신의 미션이다. post-AGI는 다른 분들이 할 일이다.
물론 자기를 불러주면 나는 협력적인 사람이니까 참여하겠다. 근데 내 임무는 AGI를 안전하게 넘기도록 세계를 돕는 거다. 그리고 안식년을 가지고 싶다.
그 후에는 뭐 그런 얘기를 하면서 이번 편을 마무리했습니다.
Demis가 어떤 인물인지를 오히려 'The Thinking Game' 편보다도 잘 알려주는 편이었던 것 같아요. 되게 솔직한 얘기들을 많이 했거든요.

<span class="paragraph-timestamp" data-ts="41:12">41:12</span> **노정석** 머리 많이 쓰시는 분들은 탈모가 정말 빨리 오네요. Ilya Sutskever도 그렇고

<span class="paragraph-timestamp" data-ts="41:18">41:18</span> **최승준** 뭐 아닌 분들도 물론 있긴 하죠. 그래서 저희가 여기 좀 쭉 한번 다뤄봤고요.
그래서 roon이라는 분이 그 OpenAI의 tech staff 중에 한 분일 거라는 소문이 있지만 확인된 바는 없고요.
근데 재밌는 이야기들 많이 하는데 여기서 어떤 AI에 대한 비판론을 조금 다시 한번 반론하는 얘기를 오늘이었나요? 어제 새벽에 올렸었고요. 그래서 오늘 저희가 소개했었던 얘기들 비슷한 거를 roon도 한번 짚었습니다.
기계 지능을 1급 생산 요소로 두고 태어나는 새로운 형태의 조직들을 볼 수 있다.
이 부분이 좀 인상에 남았고요.

<span class="paragraph-timestamp" data-ts="41:57">41:57</span> **노정석** 저희가 AI, AI-native company라고 요새 얘기하고 있는 그런 거죠.

<span class="paragraph-timestamp" data-ts="42:05">42:05</span> **최승준** 기계 지능을 1급 생산 요소로 두고 태어나는 새로운 형태의 조직들이 있다. 이런 얘기들을 했고, 그런데 이거를 제가 재미있게도 이분이 한 말에 아까 그 강조 표시한 부분을 fact check를 해보라고 했더니 요새 GPT-5.2가 fact check를 아이러니하지만 잘하거든요.
hallucination이 있는 LLM 모델이지만 조사할 수 있는 도구들이 있다 보니까 fact-checking을 또 꽤 제법 잘하는 걸 볼 수도 있는데 재미있습니다.

대체로 사실, 부분 사실, 그리고 그거에 대한 정확한 그 어떤 인용 같은 것도 해주고 근거 있다. Terence Tao가 이걸 했던 건 뭐 사실이다. 강한 추측이 있다. 단정하기는 어렵다. 이 부분은 거짓, 과장 가능성이 매우 크다. 그래서 fact check 한 번만 해달라고 해도 이런 것들이 나오는 요즘입니다.

## Andrej Karpathy의 2025년 AI 연말 결산    *42:52*

<span class="paragraph-timestamp" data-ts="42:54">42:54</span> **최승준** 벌써 거의 1시간 했는데요. 연말 결산, 이거 Andrej Karpathy가 또 연간 리뷰해 줘서 타임라인에 이미 많이 돌았던 것 같은데요. 그래서 올해 무슨 일이 있었나. 또한 Karpathy는 좀 중립적인 편이니까 뭐 유령 대 동물, 새로운 레이어, Cursor나 LLM, 그리고 Claude, Codex, 그다음에 vibe coding이나 뭐 이미지 모델의 혁신, LLM GUI, 그러니까 Generative UI 쪽도 후반부에 큰일이 있었죠.
네, 그리고 결론은 "안전벨트를 매세요"였습니다.

<span class="paragraph-timestamp" data-ts="43:29">43:29</span> **노정석** 저희 회사 엔지니어 중에 한 분이 그 얘기하시더라고요. AI가 UI layer를 다 써주는데 저희 회사는 Next.js 위에서 모든 게 빌드가 되어 있는데 Next.js 왜 써야 되냐. 그냥 바로 native JavaScript 쓰면 되는데 그 프레임워크 걷어내자, 뭐 이런 얘기를 하시더라고요.

<span class="paragraph-timestamp" data-ts="43:47">43:47</span> **최승준** 저 요새는 하여튼 뭐 관련해서 얘기할 거는 또 여러 가지 생각나는데 시간 관계상 일단 넘어가겠습니다. Gemini 3 Flash가 또 나왔죠. 네, 빠르더라고요. 물론 성능은 약간 아쉬움이 있을 수도 있지만 어떤 이렇게 딱 맞는 fit이 맞는 공간들이 있을 거잖아요. 그래서 하여튼 나왔습니다.

<span class="paragraph-timestamp" data-ts="40:14">40:14</span> **노정석** 맞아요. 예.

<span class="paragraph-timestamp" data-ts="44:09">44:09</span> **최승준** 그리고 하여튼 Flash가 나왔고 그래서 모델들은 계속 나오고 있고요. 지금 크리스마스가 4일 남았는데 아직도 쉬지를 않는 느낌이에요. 이분들 연말 휴가는 언제 가나요? 이제 가겠죠.

<span class="paragraph-timestamp" data-ts="44:21">44:21</span> **노정석** 못 가지 않을까, 못 가지 않을까요? 예, 이게 거의 뭐 치킨 게임입니다. 계속 나오고 있고, 네.

<span class="paragraph-timestamp" data-ts="44:30">44:30</span> **최승준** 그렇죠. 이게 나오는 이유들이 있거든요. 사실 지금 되게 OpenAI도 기로에 서 있고 기로라는 표현은 좀 그렇지만 어쨌든 압박을 굉장히 많이 받고 있고 지금 서로 이렇게 눌러줘야 된다고 해야 할지 확인시켜 줘야 된다고 할지 증명해야 된다고 할지 그런 일들이 연말인데도 계속 일어나고 있는데요.

<span class="paragraph-timestamp" data-ts="44:48">44:48</span> **노정석** OpenAI랑 구글이 좀 투톱으로 튀어나가고 Anthropic은 코딩 해자를 팠는데 그 부분이 살짝살짝 좀 얇아지는 그런 느낌적인 느낌 정도 있는 것 같습니다.

<span class="paragraph-timestamp" data-ts="44:59">44:59</span> **최승준** Sonnet 4.7도 소문이 있더라고요. 그래서 그게 또 Opus 4.5급의 성능이 4.7의 빠르기나 그런 것들을 가진 게 아닐까 이런 추측 같은 것들이 좀 타임라인에서 보이고요. 그런데 아직 확인된 바 없습니다.
최근에 Claude가 장애가 좀 있었는데 그럴 때 모델을 실험하느라 장애가 있었느냐라는 이상한 추측 같은 것들도 있기도 했었고요.
그다음에 GPT-5.2는 이건 The Information 기사였는데요. 그저 early checkpoint라는 소문도 있습니다. 그래서 계속 이렇게 내보내고 있는 거죠.

그리고 이게 이제 GPT-5.2가 이렇게 기반이 되는 게 저번에 저희가 얘기했던 그 2탄 들어가는 뭐죠? Shallotpeat이었나, 그 모델이 아니라 Garlic이라는 코드명을 가진 모델인데 이게 early checkpoint고 full-blown Garlic은 내년 초에 만나게 될 거다 그런 얘기들이 있습니다. 그리고 정석님이 좀 많이 살펴보셨다고 하는 NVIDIA Nemotron, 이게 뭔가요?

## NVIDIA Nemotron과 하이브리드 아키텍처의 미래    *45:54*

<span class="paragraph-timestamp" data-ts="45:58">45:58</span> **노정석** NVIDIA Nemotron이 Llama처럼 NVIDIA가 완전히 공개한 모델인데 제가 이걸 재미있게 살펴보는 이유는 데이터셋과 training recipe들, 코드 포함해서 전부 다 공개가 돼 있어요. 전부 공개돼 있어서

<span class="paragraph-timestamp" data-ts="46:13">46:13</span> **최승준** 그냥 오픈 모델이 아니라 오픈 소스인 거네요.

**노정석**
완전 오픈 소스예요. 그리고 NVIDIA 입장에서는 이런 것들을 하는 사람이 많아져야 하니까 이런 recipe들을 만들어서 모두에게 뿌릴 인센티브가 충분히 있는 거거든요. 많아져야 칩을 사는 사람들이 훨씬 많아질 테니까요.

그런데 Nemotron이 저희가 지금껏 이야기했었던 pre-training이라든지 SFT, 그다음에 RLHF, 그다음에 RLVR, 그다음에 수학과 science, 그다음에 코딩, 이런 부분의 데이터셋, 이런 부분들도 자기네들이 만든 것까지 다 공개하고 그게 어떻게 되어 있는지를 전부 다 그냥 GitHub에 올려놔서 제가 이걸 요새 열심히 보고 있어요.

저도 그냥 느낌상 우리는 어디로 도망가야 할 것인가라는 그런 질문에 대한 답으로 첫째는 당연히 현실의 문제를 지금 현재 frontier 모델의 harness를 가지고 만드는 건데 또 뒤에서 드는 기시감은 이 computation 대비 효율이 계속 증가하고 있거든요. 알고리즘의 증가, 데이터셋의 증가, 데이터셋의 오픈, 이런 것 때문에 어쩌면 Andrej Karpathy가 얘기하던 cognitive core 같은 수준, 한 10B 파라미터 이하에서도 하나의 비즈니스는 완벽하게 커버하는 그런 모델들이 나올 것 같아요.
그리고 그런 것들을 학습시켜 주는 RLVR 환경의 회사들도 조금 새로운 SI 회사로 생겨날 거고 그런데 이게 차이가 있다면 그런 걸 하기 위해서 갖춰야 하는 어떤 기본 정보들이 굉장히 많다는 것들이 이제 차이고요.

그래서 그런 세상이 올 것 같아서 저는 harness를 만드는 것 플러스 이 model work도 training과 그다음에 fine-tuning하고 RLVR 하고 evaluation하는 것들의 loop도 어떤 비즈니스 로직 안에서도 안에서 가지고 있어야 될 것 같다는 생각은 하고 있거든요. 그래서 그 부분 저희 회사도 내재화하려고 노력하고 있는데 Nemotron 얘기로 다시 돌아오면 저희가 SSM이랑 Mamba 이야기가 한 1~2년 전, 한 1년 반 전에 한 번 크게 왔었고 24년 말 정도에 Falcon 같은 데서 Mamba-based 모델 만들어내고 했었는데 이게 SSM이랑 Mamba가 굉장히 재밌거든요.

이것도 언제 한번 저희가 어떻게 만들어졌는지에 대해서 리뷰를 하면 좋을 것 같은데 그냥 intuition만 얘기하면 그래요. 저희가 처음에 RNN 있었죠. RNN 가지고 사실상의 language modeling은 RNN 가지고 했었고 그런데 그게 맨 마지막에 context vector 하나만 가지고 모든 맥락을 다 추론해야 하니까 성능이 잘 안 나온다.

그래서 거기에서 나온 게 attention 모델이었거든요. 복잡하게 앞에서 input으로 들어왔던 그런 context에 대해서 hidden activation들을 전부 다 가지고 있고 추론을 할 때마다 걔를 한 번씩 더 쓰는 그래서 attention을 하면 이 문제가 완전히 해결된다는 게 나왔던 건데 그래서 그 attention logic만 딱 떼서 나온 게 Transformer잖아요.

그래서 Transformer가 해결했던 게 RNN은 inference 하는 데는 매우 효율적인데 training 하는 게 parallelize가 안 돼서 문장을 다 읽어야만 training을 할 수 있었고 그 사이에 vanishing gradient나 exploding gradient나 이런 문제들이 발생했던 게 문제였는데 이걸 해결한 게 Transformer였거든요.

그런데 Transformer의 나쁜 점은 parallelize는 되는데 얘는 그 안에서 attention logic 계산하는데 항상 length가 길어지면 inference 할 때 context length가 길어지면 이 계산량이 O(n²)으로 quadratic하게 증가한다는 게 Transformer의 문제였잖아요. 물론 이걸 해결하는 수많은 logic들이 나오고 grouped-query attention이나 혹은 연산 과정에서의 FlashAttention이나 이런 것들이 나와서 많은 부분 좋아졌지만 그래도 RNN의 효율은 따라갈 수가 없어요.

그럼 여기서 질문이 너무너무 당연하게 나오죠. RNN의 강점만 가져가고 Transformer의 강점만 가져가면 어떻게 될까 RNN처럼 그냥 inference time에 매우 효율적인 구조를 가지고 Transformer처럼 학습 시에 parallelizing을 할 수 있으면 얼마나 좋을까 그 intuition을 만든 게 SSM이거든요.
그 SSM이 갖고 있는 몇 개의 문제를 조금 해결한 게 Mamba인데 보면 그 사이사이는 그냥 RNN 느낌이랑 매우 비슷하고 그 논문 자체는 그냥 제가 느끼기에 수학적 trick이에요. 재밌어요. 재밌는 건 이 Nemotron이 완전 Mamba-based예요.

그런데 Mamba가 갖고 있는 문제는 얘는 RNN처럼 하나의 context vector 안으로 이 sequence를 다 요약하는 그런 느낌이고 attention은 token들 사이의 관계를 끊임없이 계산하는 느낌이고 그래서 RNN은 요약에 능하고 Transformer는 관계를 기억하는 것에 능하고 이런 것들에 서로의 장단점이 있는데 요새 나오는 모델들이 이 hybrid라고 그러거든요.

예를 들어 지금 현재 우리가 익숙한 Transformer 모델들이 소위 Transformer block이 몇십 개 쌓여 있잖아요. Nemotron은 Mamba block이 한 8개 쌓인 거 위에 self-attention 놓고 그리고 그 사이에 FFN 놓고요. 그 MoE 방식으로 FFN은 똑같이 들어있는 거고 또 Mamba block이 8개씩 쌓이고 그 위에 attention block이 하나 있고 그래서 그 그룹이 한 8~9개가 구성돼 있는 구조로 돼 있거든요.
그래서 30B 전체 크기의 한 3B 정도 activation 되는 모델로 돼 있는데 무지하게 빨라요. 그냥 몇 배라고 해서 저는 이게 한 1년 반 전에 탄생을 했는데 이 hybrid, 이것도 일종의 새로운 알고리즘 유전자잖아요.

이 모델로 또 세상이 많이 굴러가겠구나 이 hybrid로 해놓은 것의 이점이 압도적으로 크기 때문에 계산 부분에서, 그다음에 inference time에서 훨씬 적은 연산량과 적은 모델 사이즈로 Transformer보다 조금은 더 나은 몇 배 낫다는 표현은 지금은 조금 위험한 것 같은데 이걸 내고 있기 때문에 저의 개인적인 예상은 다음 세대 frontier도 이런 hybrid Mamba 플러스 Transformer hybrid 모델로 이동할 가능성이 매우 높겠다는 생각이 들어요.

<span class="paragraph-timestamp" data-ts="52:43">52:43</span> **최승준** 방금 말씀하신 게 대안적인 유전자라고 표현해 주신 부분이 어떻게 보면 되게 중요한 포인트인데 대안적인 아키텍처가 사실은 그걸로 scaling 넣을 만큼 투자가 없었는데 작동하는 게 보여지면 우후죽순 또 아키텍처를 갈아 끼울 수 있는 거잖아요.

<span class="paragraph-timestamp" data-ts="52:59">52:59</span> **노정석** 맞아요. 그래서 이런 게 나온 게 몇 개 안 돼요. 몇 개 안 되는데
Nemotron이 거기를 꾸준히 밀어서 여기에서 또 한 번 작은 연산량 가지고 이 frontier에 준하는 자신들의 domain에 맞는 모델을 만들 수 있다는 게 증명이 되면 사실은 모든 vertical들도 이 방향으로 뛸 거고 싶은 인센티브가 생기는 거니까
NVIDIA 입장에서는 이 프레임워크와 자기네 칩 더 팔아서 좋은 거고
저희 같은 회사 입장에서는 이런 프런티어에 준하는 knowledge들과 레시피들과 코드 데이터셋까지 다 주는 거니까 이거는 좀 깊이 살펴볼 필요가 있겠다라는 생각이 들어서 이 Nemotron 파인튜닝과 RLHF는 제가 좀 직접 한번 해보려고 지금 고민하고 있습니다.

<span class="paragraph-timestamp" data-ts="53:52">53:52</span> **최승준** 결국에는 초반에 말씀하셨던 것처럼 약간 헤징을 해야 되는 거군요. 그냥 기존의 프런티어 쪽으로도 하는 대로 모델 이미 나와 있는 harness들을 구축하는 것도 해야 되지만 가능한 곳에서는 model work도 좀 현재의 그런 어떤 상황들을 파악해서 파고들면 이제 어디로 갈지 모르니까 어디서 gain을 얻을지 모르니까.

<span class="paragraph-timestamp" data-ts="54:10">54:10</span> **노정석** 네, 근데 모델을 포기할 수가 없는 게 지금 대부분의 value capture, 그 가치를 잡아내는 구간은 전부 모델 회사에 있거든요. 그러니까 모델 회사가 아닌 다른 회사들은 전부 굉장히 얇은 영역에서 경쟁해야 되거든요.

<span class="paragraph-timestamp" data-ts="54:26">54:26</span> **최승준** 아까 얼핏 말씀하셨지만 새로운 형태의 인프라를 다루는 TML 같은 그런 회사가 또 있기도 하고 그래서 어쨌든 그런 얘기들이 있었고 다음에 한 번 깊이 들어가면 또 흥미로운 세션이 될 것 같습니다.

<span class="paragraph-timestamp" data-ts="54:37">54:37</span> **노정석** 한번 SSM 만담은 해보시죠.

## 샤오미(Xiaomi) 등 최신 AI 모델 동향    *54:40*

<span class="paragraph-timestamp" data-ts="54:40">54:40</span> **최승준** 샤오미 이것도 정석님이 한번 알려주셔서 저도 찾아봤었는데 샤오미도 하네요.

<span class="paragraph-timestamp" data-ts="54:45">54:45</span> **노정석** paper도 읽어보지는 않았고 abstract만 봤는데 어디 다른 모델 그냥 가져와서 흉내 낸 게 아니라 from scratch로 자기네가 진짜 한 거 맞아요. 그래서

<span class="paragraph-timestamp" data-ts="54:56">54:56</span> **최승준** 요새 한국도 from scratch로 하고 있긴 하잖아요. 그래서 중국은 지금 워낙에 치고 나가고 있어서 긴장감을 가지게 하는 것 같습니다.

<span class="paragraph-timestamp" data-ts="55:07">55:07</span> **노정석** 느낌상 중국은 그냥 미국 레벨이에요. 제가 보면 그렇죠.

<span class="paragraph-timestamp" data-ts="55:12">55:12</span> **최승준** 어떻게 보면 현재 지금 2강인 거죠. 하여튼 그런 시절이고 그다음에 역시 중국 쪽의 모델인데 이제 레이어를 이렇게 따주더라고요. 그러니까 생성이 레이어로 된 거죠. 레이어를 따는 게 아니라.

<span class="paragraph-timestamp" data-ts="55:28">55:28</span> **노정석** 이거 써봐야 되겠네요.

<span class="paragraph-timestamp" data-ts="55:30">55:30</span> **최승준** 그리고 Yao Shunyu라는 또 OpenAI에 있던 분이 텐센트로

<span class="paragraph-timestamp" data-ts="55:36">55:36</span> **노정석** 스타 연구자인데 텐센트로 이직했죠.

<span class="paragraph-timestamp" data-ts="55:40">55:40</span> **최승준** 그래서 이제 피곤해서 이거를 다룰 수 있을지 모르겠는데 Simon Willison이 이제 다시 약간 바닥으로 내려와서 오늘의 할 수 있는 것들 막 이렇게 재밌는 글을 올려준 게 있거든요. 그래서 JustHTML이라는 거가 그 Simon Willison이 한 게 아니고 그걸 한 분의 이야기를 인용한 건데 상당히 흥미로운 얘기들이 있었어요.
이거를 어떻게 했는지. 그래서 굉장히 많은 테스트를 만들고 아주 작은 단위로 진전시켜 가지고 뭔가를 porting하거나 새로 만드는 그런 어떤 과정들을 펼쳐 놓은 건데
제가 이거를 일주일 전엔가 읽었을 때는 상당히 재미있게 읽었는데 지금은 또 벌써 더 기억이 잘 나지는 않습니다. 근데 한번 관심이 있으 신 분들은 이거를 실제로 어떻게 했는지를 살펴보시면 또 인사이트를 얻으실 수 있을 것 같습니다.

## 마무리 및 다음 에피소드 예고    *56:31*

<span class="paragraph-timestamp" data-ts="56:31">56:31</span> **최승준** 그래서 연말인데도 매주 뉴스가 정보가 끊이질 않습니다.

<span class="paragraph-timestamp" data-ts="56:38">56:38</span> **노정석** 기계는 계속 돌고 있으니까요. pre-training 코드와 RLHF 코드는 이 시간도 힘차게 돌고 있기 때문에 그런 거 아닐까요?

<span class="paragraph-timestamp" data-ts="56:45">56:45</span> **최승준** 그러니까요. 저희가 올해를 마무리하는 에피소드를 한 번 더 녹화할 기회가 있나요?

<span class="paragraph-timestamp" data-ts="56:52">56:52</span> **노정석** 아마도 그렇겠죠. 한 번 정도는 더 있죠. 27일에 저희 성현 님과 올해를 정리하는 그 녹화를 한번 하기로 했지 않습니까? 올해 프런티어는 어떻게 진보했나 이야기가 될 것 같은데 그때 마지막으로 한 번 더 모델 이야기하게 되지 않을까 싶습니다.

<span class="paragraph-timestamp" data-ts="57:11">57:11</span> **최승준** 정리를 하기 위해서는 소식이 없어야지 이제 회고를 할 수 있는데 그 주에도 소식이 또 있어 버리면 곤란해집니다. 자, 오늘은 여기까지 하시죠.

<span class="paragraph-timestamp" data-ts="57:15">57:15</span> **노정석** 네, 오늘 또 훑어봤습니다.

<span class="paragraph-timestamp" data-ts="57:20">57:20</span> **최승준** 예, 훑어만 본 것 같아요. 깊이 들어간 거는 그렇게 많지는 않은데, 예, 알겠습니다.

<span class="paragraph-timestamp" data-ts="57:23">57:23</span> **노정석** 네, 수고하셨습니다.

<span class="paragraph-timestamp" data-ts="57:23">57:23</span> **최승준** 네, 수고하셨습니다.