---
episodeNumber: 78
title: "Ilya Sutskever의 설명"
description: "Ilya Sutskever가 던진 한마디가 왜 AI 커뮤니티를 들끓게 했을까요? 이번 에피소드에서는 Ilya Sutskever가 출연했던 Dwarkesh Patel 팟캐스트의 핵심을 해부하..."
publishedAt: 2026-01-28
duration: "56:09"
youtubeId: "Tm-rxPN2XWo"
thumbnail: "https://i.ytimg.com/vi/Tm-rxPN2XWo/maxresdefault.jpg"
hosts:
  - 노정석
  - 최승준
  - 김성현
chapters:
  - time: "00:00"
    title: "오프닝: Ilya Sutskever와 '연구의 시대' 선언"
  - time: "01:17"
    title: "스케일링 논쟁: 경제·안보 문제로 확장된 AI"
  - time: "03:59"
    title: "인물 소개: Ilya Sutskever"
  - time: "05:15"
    title: "Ilya의 해명과 Noam Brown의 정리: 스케일링과 연구의 갭"
  - time: "07:34"
    title: "연구자들의 합의점과 '지속 학습(Continual Learning)'의 필요성"
  - time: "13:40"
    title: "놀라운 능력과 어처구니없는 실수의 공존 (RL 스케일링의 한계)"
  - time: "19:44"
    title: "감정은 가치 함수다: 제한된 합리성과 휴리스틱"
  - time: "24:30"
    title: "'괴델, 에셔, 바흐(GEB)'와 AGI의 탄생 조건 (이상한 고리)"
  - time: "30:35"
    title: "진정한 지능은 모델이 아니라 시스템이다"
  - time: "32:16"
    title: "인간의 샘플 효율성과 내적 동기 (사회적 욕구)"
  - time: "34:29"
    title: "일반화(Generalization)와 귀납적 편향(Inductive Bias)"
  - time: "39:17"
    title: "초지능(ASI)으로 직행하기: 모든 것을 배울 수 있는 씨앗"
  - time: "43:42"
    title: "좋은 연구를 위한 '취향(Taste)'과 안목"
  - time: "45:59"
    title: "양질 전환과 에너지가 높은 토큰"
  - time: "48:10"
    title: "OpenAI 과학팀 일화: 블랙홀 연구자와 GPT Pro의 협업"
  - time: "51:04"
    title: "Claude Opus 4.5 실전 테스트: 2줄로 만드는 'CloudBook'"
  - time: "53:00"
    title: "장기 실행 에이전트와 기억의 외재화 (Harness)"
  - time: "55:23"
    title: "클로징: 도망자 연합과 마무리"
lang: "ko"
alternateSlug: null
notionUrl: "https://erucipe.notion.site/2b9d5c9e7e59800cbd9cfdb5b4d4ecbc"
---

## 오프닝: Ilya Sutskever와 '연구의 시대' 선언    *00:00*

<span class="paragraph-timestamp" data-ts="00:00">00:00</span> **노정석** 녹화를 하고 있는 오늘은 2025년 11월 29일 토요일 아침입니다. 이번 주에 가장 큰 소식을 꼽으라면 아무래도 Ilya Sutskever와 Dwarkesh Patel의 팟캐스트일 겁니다.

Ilya Sutskever가 현재의 pre-training은 벽에 도달했다. 무언가 새로운 생각이 필요하다. 이제 스케일링의 시대는 가고 연구의 시대가 다시 도래했다 이런 얘기들을 중심으로 얘기하면서 커뮤니티가 한 번 술렁였죠. 그 임팩트가 컸는지 좀 수정한 트윗도 올라왔고요. 승준님이 요약을 한번 해 주시죠.

<span class="paragraph-timestamp" data-ts="00:37">00:37</span> **최승준** 지금 말씀하시는 거 들어보니까 Claude Opus 4.5가 묻혔네요. Ilya Sutskever 얘기에

<span class="paragraph-timestamp" data-ts="00:40">00:40</span> **노정석** 살짝 그런 면도 있습니다만 엔지니어들 사이에서는 Claude Opus 4.5가 매우 똑똑하다. 그래서 Antigravity와 Claude Opus 4.5를 왔다 갔다 서로 토큰 리밋이 오면 저기로 갔다가 여기로 왔다가 그게 좀 잡힌 것 같습니다.

<span class="paragraph-timestamp" data-ts="00:55">00:55</span> **최승준** 그래서 이번 주도 기대했던 것들이 일단은 모두 다 밝혀진 상황에서 저희가 Ilya Sutskever에 대한 이야기를 하는 걸로 시작을 했는데 제목을 일단 '일리야 토큰'으로 뽑아왔습니다. 그래서 오늘 새벽에 워낙 타임라인이 들끓었는지 정리하는 글을 Noam Brown이 올리긴 했는데요. 타임라인이 들끓은 것을 성현님 어떻게 보셨나요? 왜 이런 일들이 발생하고 있나요?

## 스케일링 논쟁: 경제·안보 문제로 확장된 AI    *01:17*

<span class="paragraph-timestamp" data-ts="01:20">01:20</span> **김성현** 만약 AI라는 영역 자체가 학문적인 영역이었으면 이런 문제가 발생하지 않을 것 같긴 합니다. 학문적인 영역에서는 계속 이런 논쟁은 있었거든요. LLM이 된다, 안 된다, Yann LeCun을 위시로 해서 그런 논쟁들도 있었고 그건 늘상 있는 일이죠. 그런데 저는 스케일링이라는 주제 자체가 너무 큰 경제적인 영역 문제들과 연결되기 시작한 것 같아요. 저로서는 약간 당황스럽기도 하고 굉장히 조심스럽게 만드는 부분이기도 한데 스케일링이라는 화두가 되면서 그렇다면 데이터 센터를 많이 지어야 한다. 어마어마한 투자를 해야 한다.

데이터 센터를 많이 짓는다는 게 그냥 GPU를 많이 산다는 것뿐만 아니라 전력 인프라도 있어야 되고, 그 인프라를 준비해야 하고, 결국은 투자 금액이 커지다가 이것은 정부 보증이 있어야 한다 이런 수준까지 나아가고 있잖아요. 그렇다 보니까 그 스케일링이라는 게 정말 효과적인가, 그렇게 투자하는 게 정말로 가능성이 있는 일인가, 그렇게 투자하면 AGI가 오는 것인가, 이 주제가 그냥 학문적인 문제가 아니라 사회 경제적인 문제가 된 것 같습니다. 국가적인 문제가 되는 것 같기도 하고 어떤 경우에는 미국과 중국 사이의 갈등이라는 형태로 안보적인 이슈가 되는 것 같기도 하고요. 모든 경제적인 영역과 국가 안보적인 영역에 영향을 미치기 시작한 거죠. 그렇기 때문에 이게 더 들끓는 것 같습니다.

비슷한 패턴이 GPU하고 TPU 논쟁 때문에 발생하는 것 같거든요. 구글이 TPU를 쓰고 있다는 걸 AI 엔지니어 중에 그걸 모르는 사람은 아무도 없었을 겁니다. 구글은 예전부터 Gemini 1.0부터 TPU를 써왔고요. Gemini 3에서 TPU를 썼다는 건 당연한 거죠. 그 이전에도 썼으니까요. 그런데 그 TPU를 썼다는 소식이 어떤 다른 형태의 집단의 사람들에게 구글이 TPU를 쓰고 있다는 걸 몰랐던 사람들한테 전해지기 시작하니까 그게 엄청난 파급 효과를 일으키더라고요. 아마 주식 시장에도 실제로 영향이 미치지 않았을까 싶습니다. 그러니까 NVIDIA가 해명을 하게 되죠. GPU하고 TPU는 다르다. GPU는 경쟁력이 있다 이런 해명을 하더라고요.

<span class="paragraph-timestamp" data-ts="03:21">03:21</span> **최승준** 속된 말로 하면 판돈인 거군요.

<span class="paragraph-timestamp" data-ts="03:26">03:26</span> **김성현** 너무 커진 거죠. 너무 커지고 이 사실 하나에 달린 많은 문제들이 너무 큰 것 같습니다, 요즘은.

<span class="paragraph-timestamp" data-ts="03:33">03:33</span> **노정석** 사실 지난 일주일 동안 주식 시장은 성현님이 말씀하신 대로 정확히 그렇게 움직였거든요. 그래서 구글이 Gemini 3를 NVIDIA GPU를 안 쓰고 만들었다는 그 사실 하나 때문에 구글 주가는 굉장히 오르고 NVIDIA 주가는 출렁였죠. 휘청거렸다고 표현하는 게 맞겠네요.

<span class="paragraph-timestamp" data-ts="03:54">03:54</span> **최승준** 그런 일이 있었군요. 그러면 일단 Noam이 뭐라고 얘기했는지 한번 보고 다시 돌아와 보죠.

## 인물 소개: Ilya Sutskever    *03:59*

<span class="paragraph-timestamp" data-ts="04:03">04:03</span> **노정석** 저희가 이 이야기를 논의하기 전에 Ilya Sutskever, Noam Brown, Andrej Karpathy 이런 분들을 모르는 분이 많이 있으실 것 같아서 Ilya Sutskever는 매우 전설적인 Geoffrey Hinton의 제자이자 AlexNet을 처음 만들었던 전설적인 AI 연구자고, 구글에 가서 sequence-to-sequence RNN 모델을 만들어서 language translation도 만들었고, 그리고 나서 OpenAI에 옮겨 왔다가 지난번에 Sam Altman과의 어떤 경영권 분쟁으로 OpenAI를 떠난 AI 시대를 대표하는 아이콘이죠. 그래서 이 사람이 무슨 말을 하든지 시장이 출렁이고 약간 선각자 모세와 같은 그런 역할을 하고 있지 않나 하는 생각이 듭니다. 그만큼 무게가 있는 인물이 한 얘기이기 때문에 저희가 주의 깊게 들어볼 필요가 있는 거죠.

<span class="paragraph-timestamp" data-ts="04:50">04:50</span> **최승준** 그래서 이번에 Dwarkesh Patel의 Ilya Sutskever 인터뷰가 두 번째예요. 첫 번째가 GPT-4가 나온 2023년 3월에 있었거든요. 그래서 이게 지금 두 번째 인터뷰고 그 인터뷰가 Sutton 편하고 비슷하게 또 Andrej Karpathy 편도 비슷하게 Dwarkesh가 지금 그런 큐레이션을 하고 있어요. 다른 지평을 보여주려고 하는 큐레이션을 하고 있다 보니까 그게 이제 논쟁들을 불러일으키고 있고 어떻게 보면 건강한 방향성일 수도 있다고 생각합니다.

## Ilya의 해명과 Noam Brown의 정리: 스케일링과 연구의 갭    *05:15*

<span class="paragraph-timestamp" data-ts="05:16">05:16</span> **최승준** 그런데 새벽에 Noam이 좀 정리를 해줬어요. 그래서 Ilya Sutskever는 자기가 Dwarkesh 인터뷰에서 했던 이야기 중에 전달되지 않은 포인트가 있다. 누가 자기를 인용해 가면서 정리한 부분을 리트윗했는데 그거를 인용하면서 한 얘기예요. 지금의 방법을 더 키워나가면, 계속, 그러니까 스케일링하면 계속 성능 향상이 있을 것이지, 없다고 얘기하는 게 아니라 약간 갭이 있다는 정도로 얘기했다. 그래서 특히 이게 중간에 멈춰버리지는 않을 것이라고 한 번 더 보완을 해 줬고요. 다만 그럼에도 불구하고 여전히 어떤 중요한 무언가는 계속해서 빠져 있을 것이다. 그래서 자기의 포인트는 여기를 좀 얘기한 거라고 트윗을 올렸어요.

그런데 그것을 Noam이 조금 더 뻥튀기해서 설명을 해줬거든요. 그래서 Noam이 강조한 것은 지금 회의론자와 광신도가 있는데 연구자들이 하는 얘기를 들어보면 수렴되는 지점이 많다. 지금의 패러다임만으로도 추가적인 연구적 돌파구가 없어도 막대한 경제·사회적 임팩트를 내기는 충분할 가능성이 크다. 그런데 정말 AGI, ASI로 가려면 지속 학습이나 샘플 효율 등 추가적인 돌파구가 더 필요할 확률이 높다. 그런데 우리는 그런 돌파구를 찾아낼 것이고 20년 안에는 거기에 도달할 것이다.

그런데 이 예측은 각 선구자들마다 다르다. Hassabis는 5에서 10년, Chollet은 5년, Sam Altman은 수천 일, Yann LeCun은 10년, Ilya Sutskever는 5에서 20년, Amodei는 가장 공격적으로 2년 안에도 가능하다고 얘기를 했다. 그래서 누구도 100년까지 걸릴 거라고는 아무도 얘기하지 않는다. 전체적으로 보면 동의하는 부분이 서로 다른 부분보다 훨씬 많다고 정리를 해줬습니다.

그리고 Andrej Karpathy가 지난번에 올렸던 것까지 인용해서 쭉 소개를 해줬거든요. 그래서 Karpathy도 Dwarkesh 출연 다음에 한 번 또 정리하는 글을 올렸어요. 그래서 그 내용은 제가 번역해 놨으니까 여기 링크를 통해서 살펴보시면 될 것 같습니다. 그래서 일단 이 지점에서 저희가 좀 더 얘기할 게 있을까요?

## 연구자들의 합의점과 '지속 학습(Continual Learning)'의 필요성    *07:34*

<span class="paragraph-timestamp" data-ts="07:36">07:36</span> **김성현** 여기서도 이야기할 수 있을 것 같은 게, 저는 여기서 Noam Brown이 연구자들 생각은 비슷하다고 얘기하는 게 맞다고 봅니다. 왜냐하면 저 같은 경우도 첫 세션에서 continual learning에 대한 언급을 했었잖아요. 그게 제 아이디어로 온 건 아니고 저도 그때 연구자들이 하는 이야기를 듣고 요즘 이런 연구들이 일어나고 있고 이런 문제의식을 가지고 있다는 걸 소개해 드린 거였거든요. 그렇기 때문에 굉장히 저로서는 자연스러운 이야기라고 느껴졌습니다. Ilya Sutskever가 한 얘기도 그렇고요. 이게 도리어 왜 저는 이상하게 들렸는지가 오히려 궁금하기는 해요.

비슷한 일이 사실 없었던 게 아니거든요. pre-training의 스케일링이 제일 큰 첫 번째 패러다임이었죠. pre-training의 스케일링만으로 지금 나와 있는 모델의 성능 향상이 일어난 건 아니거든요. 분명하게 pre-training의 스케일링만으로 지금 수준의 모델 성능에 도달하려고 하면 그 스케일이 어마어마해야 했을 겁니다. 그런데 그 돌파구를 찾았던 게 굉장히 연구적인 접근이었던 o1하고 RL이죠. o1과 RL을 통해서 pre-training의 스케일링 이상으로 훨씬 더 커다란 성능 향상을 끌어낼 수 있었던 것이거든요.

그렇다고 하면 사실 그런 패러다임의 발견이 앞으로도 중요하고 필요할 거라고 생각할 수 있습니다. 그게 스케일링하고 상충되는 것도 아니죠. pre-training의 스케일링하고 상충되는 건 아닌데, 그런 연구적인 발견들이나 개발들이 훨씬 더 모델을 강력하게 만들 수 있죠. 그게 여기 요약된 것과 비슷하다고 생각합니다. 그러니까 Ilya Sutskever가 요약한 것처럼 스케일링은 계속해서 성능 향상을 끌어낼 것이지만, 뭔가가 부족할 것이고, 그 부족한 것에 대해서 돌파구를 찾고 더 커다란 성능 향상 폭을 얻기 위해서는 추론과 같은 새로운 패러다임 같은 게 필요할 것이고, 그런 패러다임은 스케일링만으로 얻어지는 것은 아니고 연구가 필요한 주제죠.

<span class="paragraph-timestamp" data-ts="09:30">09:30</span> **최승준** 그래서 Ilya Sutskever 편의 제목이 ‘연구의 시대’가 부제였잖아요.

<span class="paragraph-timestamp" data-ts="09:35">09:35</span> **노정석** 저도 Ilya Sutskever가 처음 얘기했을 때 거부감을 저에게 줬던 것은 Sutton 때도 느꼈던 것과 비슷한데, 지금 현재 그냥 스케일링을 늘리는 것, 아직 스케일이 끝까지 어디까지 가는지에 대해서는 아무도 모르잖아요. 구글은 Gemini 3를 만들면서 pre-training에 대해서도 무언가를 풀었다, 뭐 이렇게 얘기를 하고 저희가 알지 못하는데 저는 이렇게 자원을, computation을 더 늘림으로써 가는 어떤 고고한 방향성의 부분이 틀렸다, 어떠한 다른 기저의 구조를 바꾸는 것만이 우리를 다음 길로 이끌 것이라고 단정하는 부분이 불편했던 것 같아요.

그런데 성현님은 사업적인 관점에서 정보들을 습득해서 받아들이는 사람이 왜 다르게 받아들이는가를 좀 궁금해하셨을 수도 있는데 어떻게 보면 지난번에 승준님이 보여주셨던 그 '괴델, 에셔, 바흐'의 그림처럼 어떤 문제의 본질은 차원을 달리하겠지만 존재하는데 지금 각자의 관점과 단어에 대한 정의와 이런 것들이 다르기 때문에 다 상들이 다르게 맺히는 것 때문에 생기는 문제이지 그 다른 상들 역시도 약간 동형성을 갖고 있다, 본질적으로는 같은 문제를 address하고 있다는 생각은 듭니다.

그래서 Ilya Sutskever도 사실 방금 말씀 주셨지만 트위터를 통해서 자신의 의견을 하나는 수정은 했잖아요. scaling law가 틀렸다는 건 아니고 계속해서 gain을 가져오겠지만 이것을 다음 단계로 점프하기 위해서는 연구가 필요하다. 당연히 동의하죠. 당연히 동의하죠.

<span class="paragraph-timestamp" data-ts="11:11">11:11</span> **최승준** 이게 재밌는데, 유진 님이 알려주셔서 저도 봤는데 이게 Dwarkesh podcast의 thumbnail이 달라졌어요. 처음에는 "It's back to the age of research, again, just with bigger computers."라고 돼 있거든요. 그냥 연구의 시대인데 그냥 더 많은 computation을 가지고 하는 거다. 그런데 pre-training이 target을 overshoot했다, 이렇게 바뀌었습니다. 소셜 미디어에서 화두가 되다 보니까 톤을 달리한 것 같긴 한데요.

무슨 말을 했는지는 조금 이따가 살펴보지만 밈이 되고 있는 게 있죠. 이게 정석님도 한번 알려주셨는데 Dwarkesh가 그래서 SSI는 어떻게 돈을 벌 건가요, 라고 물었더니 연구에만 집중하고 질문에 대한 답은 스스로 드러날 거다. 많은 가능한 답들이 있을 거라고 생각하는데 사실 Noam Brown도 비슷한 얘기를 했다고는 저는 느껴졌어요. 왜냐하면 "아마도 우리는 그런 돌파구를 찾아낼 것이다." 그래서 OpenAI는 OpenAI 나름대로 뭔가 돌파구를 찾아내려고 하고 있고 모든 top lab에서 다른 거는 뭐가 있는지를 찾아보는 건 너무 당연하잖아요. 연구를 해야 되니까.

그런데 SSI도 지금은 밝힐 수는 없지만 돈 당장 버는 것보다는 연구에 집중하는 경로로 가겠다, fundraising한 거 가지고. 그런데 그렇게 얘기한 거가 지금 좀 밈이 되고 있는 시점이긴 한 것 같습니다. 그러면 저희가 그 Ilya Sutskever의 내용을 전부 다 뽑지는 못하지만 몇 개의 슬라이드를 가지고 Claude Opus 4.5가 만들어 준 슬라이드거든요. 그래서 AI가 저희를 쓰게 해서 AI가 뽑아준 포인트를 가지고서는 좀 얘기를 해봐도 재밌을 것 같아요.

있는 얘기들을 뽑았거든요. 그래서 제가 첫 장면 소개를 좀 해드리면 이게 인터뷰 초반에 되게 informal하게 나오는 장면이에요. 그래서 막 Dwarkesh랑 Ilya가 아직 녹화 시작도 안 했는데 촬영은 걸어놓고서는 막 대화하다가 이런 말을 해요. 지금 풍경이 SF에서 튀어나온 것 같은 풍경이다, 라는 걸 하다가 Ilya가 흥미로운 말을 던지니까 Dwarkesh가 딱 분위기 잡으면서 "그러면 지금부터 한번 이야기 나눠볼까, 토론해 볼까?" 라면서 이 장면이 전개됐거든요. 그래서 다음 장이 연구의 시대, 그런데 연구의 시대에 관해서는 저희가 방금 얘기했으니까 넘어가고요. 이 부분이 좀 얘기해 볼 거리가 있는 것 같아요. '놀라운 능력과 어처구니없는 실수의 공존', 여기에 대해서 성현님이 생각하시는 게 분명히 있을 것 같은데요.

## 놀라운 능력과 어처구니없는 실수의 공존 (RL 스케일링의 한계)    *13:40*

<span class="paragraph-timestamp" data-ts="13:54">13:54</span> **김성현** 이렇게 1만 시간 경쟁 코딩 문제를 학습한 사람과 100시간만 학습한 사람의 차이, 이런 언급을 하면서 나왔던 주제인 것 같은데요. 저는 왜 이런 현상이 일어나는지를 많은 방식으로 해석할 수 있을 것 같긴 한데 저는 RL scaling의 지금 한계라는 생각을 합니다. RL scaling을 하려고 하면 결국 환경이 있어야 되잖아요. 그 환경 속에서 모델이 RL을 하고 학습을 해 나가야 되는데 그것들을 하나하나 만들어 줘야 되는 거죠. 생각해 보면 평가는 보통 자동적으로 할 수 있는 걸 원하기 때문에, 혹은 사람이 개입하더라도 최소한만 개입하면 되는 걸 원하기 때문에 평가라는 것 자체가 하나의 환경입니다. 그 환경을 target으로 해서 RL을 해 가지고 모델을 학습시킬 수가 있어요. 그러면 평가는 잘하겠죠.

그런데 문제는 그 환경이 실제로 경제적으로 가치 있는 일들, 혹은 사람들이 사용하는 것과 얼마나 관계가 있는지는 별개의 문제입니다. 그렇다고 하면 사실 사람들이 실제로 모델과 상호작용하는 방법들, 사람이 모델을 사용하는 방법들에 대해서는 거기에 맞는 환경을 만들어 줘야 될 거예요. 그리고 그 환경을 어떻게 만들 것인가가 지금 제일 큰 문제죠. 요즘 쉽게 이야기하는 bench-maxxing을 했다는 것과도 일맥상통합니다. benchmark를 target해서 학습시키면 benchmark를 잘 풀 수 있어요. 그런데 그 benchmark를 잘 푼다고 해서 그 모델이 실제로 사용 환경에서 잘 작동하리라는 보장은 없는 거죠.

그러면 여기서 굉장히 많은 문제들이 생깁니다. 그러면 그런 환경들을 어떻게 만들 것인가, 사람이 하나하나 만드는 것도 한계가 있죠. 사람이 모델을 통해서 하려고 하는 과제의 길이는 점점 길어져 가는데, 그 점점 길어져 가는 것들을 어떻게 환경을 만들어 낼 것인가, 그 환경을 실제 사람들의 사용 환경과 어떻게 더 가깝게 일치시킬 것인가, 그리고 그 환경은 결국 사람이 직접 만들어야 되는가, 모델로 만들 수는 없는가, 더 나아가서 이 특정한 환경에 대해서 학습한 모델이 새로운 환경에 대해서도 어떻게 일반화시킬 수 있을 것인가, 이런 문제들이 계속 발생하죠. 그리고 그 문제들을 어떻게 tackle할 것인가가 지금 post-training에서 각 big tech들도 경쟁하고 있는 부분일 겁니다.

이 환경을 어떻게 만들어 나가야 될 것인가에 대해서는 알려지고 있는 것들이 더 없어요. 그러니까 pre-training 시점에서도 pre-training을 어떻게 했는가, 이런 부분에 대한 것은 비밀이 많았죠. 그리고 거기에 대해서 노하우들이 많이 있었을 것이고요. 그런데 그것은 추측을 해보면 그나마 추측을 할 수 있는 영역이었습니다. 그런데 환경을 늘려나가고 post-training을 하는 영역은 더더욱 베일에 싸여 있어요. 그래서 이 사람들이 실제로 어떻게 하고 있는지 모르고 어떤 노하우가 있는지, 어떤 디테일이 있는지 잘 모르는 거죠.

그렇기 때문에 어떻게 생각하면 Gemini, Claude, 그리고 GPT-5, 이런 모델들이 frontier lab들에서 만들어지고 있지만 post-training된 결과물들이 다 다른 것일 겁니다. 왜냐하면 post-training에 대한 노하우나 이런 것들이 다 다르게 적용되고 있으니까요. 그렇기 때문에 그것 자체도 연구적인 문제라고도 할 수 있고 계속해서 그 문제를 해결해 나가기 위해서 많은 노력들이 지금도 계속 들어가고 있는 문제인 거죠. 어떻게든 RL을 더 잘해서 이런 문제들을 완화시키기 위해서 접근하다 보면 '이걸 좀 더 잘할 수 있는 방법은 없는가?' '이 문제를 좀 더 근본적으로 해결할 수 있는 방법은 없을까?' 하는 생각을 하게 되죠. 그게 아마 Sutskever가 얘기하는 문제 중 하나일 거라고 봅니다. 특히 일반화에 대한 문제하고 연관을 지어서요.

<span class="paragraph-timestamp" data-ts="17:20">17:20</span> **최승준** 그렇죠. 지금 여기서 얘기하는 게 Sutskever가 화두를 던진 게, 평가는 너무 잘하는데 어떻게 실제로 사용하다 보면 어이없는 버그를 내냐, 그러니까 benchmark를 그렇게 잘 통과하는데 이 문제는 왜 못 푸냐는 간극 같은 게 느껴지고 그게 RL을 하다 보면 약간 spiky하게 어떤 능력은 굉장히 잘하는데 빈 지점들이 있는 것 같다는 뉘앙스의 얘기를 했던 것 같고요. '1만 시간의 학생과 100시간의 학생', 아까 성현님이 잠깐 언급해 주셨던, 그래서 모델은 1만 시간 열심히 공부한 학생 같고, 100시간의 감각이 있는 학생은 아닌 것 같다는 얘기를 했었죠. 일반화 능력이 현저히 떨어지는 거예요. 모델이.

<span class="paragraph-timestamp" data-ts="18:05">18:05</span> **김성현** 예, 그렇죠. 그렇게 생각할 수 있죠. 일반화가 현저히 떨어진다고 생각할 수 있는 게, 사람이 만약 그 정도의 데이터를 학습하고 그 정도의 환경에서 학습을 했으면 새로운 문제들에 대해서도 굉장히 잘하지 않을까요? 그리고 더 나아가서는 새로운 문제라고 해도 그걸 조금만 학습하면 잘할 수 있게 되겠죠. 그런데 일반화가 굉장히 다양한 방식에서 문제가 될 수 있습니다.

방금 전에도 일반화 문제를 말씀을 드렸는데, 어떤 환경에 대해서 학습을 하면, 예를 들어서 Claude Code를 사용해서 무언가를 하는 걸 학습하면 새로운 환경에 대해서도 잘할 수 있어야 되지 않을까, 여기서도 하나의 일반화가 있죠. 그리고 더 나아가서 예를 들어서 한 5분짜리 과제를 수행할 수 있다고 하면 1시간짜리 과제로도 일반화가 되어야 되지 않을까, 이런 일반화도 존재하죠. 굉장히 다양한 축에서의 일반화가 존재할 수 있습니다. 그리고 그 일반화에 대해서 지금까지 그렇게 성공적이지는 않은 것 같아요.

사실 post-training이라는 이 패러다임에 국한해서 생각하지 않고 딥러닝이라고 하는 전체에 대해서 생각하면 일반화 문제에 대해서는 저는 진전이 거의 없다고 생각합니다. 이 아키텍처 전체가 일반화를 훨씬 더 잘하는 모델을 만든다, 이것 자체가 그렇게 성공적이었던 사례가 저는 없는 것 같아요. 지금 푸는 방법은 pre-training을 하는 거죠. 그건 데이터를 더 많이 쓰는 거잖아요. 그런데 일반화라고 하면 보통 데이터 효율적인 걸 생각하죠. 데이터를 조금 쓰고도 잘할 수 있는 것, pre-training을 같은 양의 규모로 했다고 하더라도 어떤 방식으로 pre-training을 하면 훨씬 더 잘 푸는 것, 이런 문제들을 생각하는 거죠. 그런데 그런 문제들에 대해서는 거의 진전이 없는 것 같습니다. 굉장히 어려운 문제이기도 해요. 굉장히 어려운 문제입니다. 여기에 대해서 돌파구를 찾았다거나 진전이 있었던 건 아닌 것 같습니다.

## 감정은 가치 함수다: 제한된 합리성과 휴리스틱    *19:44*

<span class="paragraph-timestamp" data-ts="19:49">19:49</span> **최승준** 근데 Sutskever가 좀 신기한 얘기를 잘 못 들어본 얘기를 했어요. 가치 함수라는 거는 RL에서는 익숙한 얘기인데 감정이 가치 함수다라는 얘기를 해서 저도 이 부분이 쉽게 와닿지는 않았었거든요.

<span class="paragraph-timestamp" data-ts="20:05">20:05</span> **김성현** 이게 그 얘기를 하는 거죠. 사람들이 주로 생각하는, 감정이 전혀 없고 완전히 합리적인, 이성만 있는 인간이라고 하면 늘 합리적이고 이성적인 선택만 하지 않을까라는 건데 실제로 그런 사람은 선택을 전혀 못 한다는 거죠.

<span class="paragraph-timestamp" data-ts="20:18">20:18</span> **최승준** 뇌 절제술이나 뭐 그런 거 얘기하면서

<span class="paragraph-timestamp" data-ts="20:20">20:20</span> **김성현** 실제로 있었던 사례이기 때문에 언급하는 것 같은데 그래서 사람들이 생각하듯 감정이 없으면 완벽하고 철두철미하게 합리적인 결정만 할 수 있을 것이다. 그런데 실제로 일어나는 일은 결정을 전혀 못 하는 상태가 되는 거죠. 아마 그 원인이 정확하게 뭔지는 제가 그 사례를 공부해 보지 않아서 모르겠는데 아마 수많은 가능성에 대해서 끊임없이 합리적, 이성적으로 생각하려다 보니까 그 정보나 가능성에 짓눌려서 선택을 못 하게 되는 그런 상태에 가까웠던 것이 아닌가 싶습니다.

감정이 있다면 그런 문제에 도움이 될 수 있죠. 우리가 합리적인 것만으로는 의사결정을 할 수 없는 경우가 많이 있거든요. 결국 불확실성 속에서 도약을 해야 하는 경우가 있죠. 그리고 그 불확실성 속에서 도약을 할 때는 감정 같은 것들이 이성과는 완전히 별개의 영역에서 작용해서 도움이 될 수 있죠. 그러면 그때 감정의 기능이 무엇일까 생각해 보면 여러 가지 가능성이 있을 수 있을 것 같은데 저도 이 문제에 대해 아주 깊게 생각해 보지는 않아서 한 가지 생각해 보면, 가치 함수라고 비유했기 때문에 그것과 결부시켜서 생각해 보면 가치 함수는 어떤 상태가 어느 정도의 보상으로 이어질 것인가에 대한 함수라고 할 수 있거든요.

그러니까 이 상태는 좀 더 큰 보상으로 이어질 거다, 어떤 상태는 크지 않은 보상으로 이어질 거다, 이런 형태인 거죠. 그런데 이게 막연히 생각하면 굉장히 합리적으로 추정될 거라고 생각할 수도 있습니다. 그러니까 이 상태, 이 환경, 이 조건이 큰 보상으로 이어질 가능성이 높다고 사람은 합리적인 이유를 통해서 이 조건이 큰 보상으로 이어질 거라고 연관 지을 수도 있겠죠. 그러나 사람의 의사결정이 실제로 그런 형태로 이루어질까, 좀 더 나아가서 세상이 그런 형태로 구성되어 있는가, 이건 좀 다른 문제일 겁니다.

세상은 불확실하고 예상 불가능한 요인들이 많이 일어나죠. 그럼 그 불확실한 상황 속에서 의사결정을 하고 '이 상태가 좋을 거야', '이 판단이 좋을 거야'라고 생각하는 건 다분히 감정적이고 믿음에 근거한 영역일 수 있습니다. 그리고 그 믿음이 굉장히 큰 도움이 될 수 있죠. 의사결정에.

<span class="paragraph-timestamp" data-ts="22:38">22:38</span> **최승준** 그래서 문득 듣고 보니까 Sutton은 거대 세계 가설 얘기하면서 제한된 합리성을 얘기했는데 Ilya는 약간 비슷하면서도 다른 톤으로 얘기하는 게 결국 감정 같은, 아직은 LLM에 부재한 어떤 것이 인간을 실행 가능한 에이전트로 만들 수 있다는 것. 거기에 뭔가 힌트가 있는 게 아닌가 라는 뉘앙스로 얘기했던 것 같아요.

<span class="paragraph-timestamp" data-ts="22:57">22:57</span> **김성현** '제한된 합리성'이라고 표현하면 합리적인 조건만으로는 모두 판단할 수 없는 어떤 문제가 있다는 거잖아요. 그때 굉장히 도움이 되는 것이 휴리스틱입니다. 예를 들어 더러운 것을 보면 피하겠죠. 그건 휴리스틱인데, 만약 정말로 합리적으로 의사결정을 하려면 실제로 더러운 것이 나에게 위험한지 아닌지를 따져봐야겠죠. 하지만 그것보다는 훨씬 더 직접적인 휴리스틱을 사용합니다. 그리고 더러운 것을 피하는 것이 가장 감정과 결부되거든요. 혐오라는 감정과 그런 식으로 다 엉켜 있다고 생각할 수도 있을 것 같아요.

그런데 저는 이 가치 함수에 대한 언급에서 Sutskever가 좀 더 머신러닝과 관련된 것으로 넘어가면서 하는 얘기가, RL에서 가치 함수가 하는 역할을 보면 좀 더 샘플 효율적으로 만들어 주고 학습을 좀 더 빠르게 만들어주는 효과거든요. 그런데 그것에 대해서라면 비효율적이지만 비슷한 일은 할 수 있습니다. 그러니까 가치 함수가 없다고 하더라도 비효율적인 방식으로 비슷한 결과에 도달할 수 있죠.

그런데 Sutskever가 얘기하는 건 그것보다 좀 더 근본적인 문제를 건드리는 것 같긴 합니다. 그냥 비효율적으로나마 도달할 수 있는 게 아니라, 비효율적으로 한다고 하더라도 도달할 수 없는 어떤 문제, 그런 문제들에 좀 더 관심이 있는 것 같긴 합니다. 가치 함수라는 것을 넘어서요. Sutskever가 이런 얘기를 많이 하긴 했습니다. 감정과 관련해서도 연구를 했었고, 이전에는 모델이 자아의식을 갖는 게 필요할 거다, 자의식이 있는 쪽이 더 유용할 거니까 이런 식의 언급을 한 적도 있고, 비슷한 얘기를 계속해 오고 있는 것 같습니다.

## '괴델, 에셔, 바흐(GEB)'와 AGI의 탄생 조건 (이상한 고리)    *24:30*

<span class="paragraph-timestamp" data-ts="24:30">24:30</span> **노정석** 그러니까 저는 이 논의에 대해서 저만의 개똥철학이 있기는 해요.

<span class="paragraph-timestamp" data-ts="24:36">24:36</span> **최승준** 궁금하네요.

<span class="paragraph-timestamp" data-ts="24:41">24:41</span> **노정석** '감정이란 무엇인가', '영혼이란 무엇인가' 이런 것들에 대해서 예전에 승준님도 좋아하시는 GEB, "괴델, 에셔, 바흐" 사실 굉장히 난해한 책이기 때문에 거기에 대해서는 해석이 좀, 시각이 분분한데, 이런 거 있잖아요. 그 괴델, 에셔, 바흐가 그 책도 증명되지 않은 사실에 대해 얘기하거든요. 그러면 그가 얘기하고 싶었던 것, 핵심은 'I, Who am I', '나는 누구인가'라는 우리 몸 안에서 돌고 있는 이 영혼이라는 시스템의 존재는 무엇인가라는 것에 대해서 이렇게 두꺼운 책을 통해 증명하고자 하는 건데, Douglas Hofstadter는 그렇게 얘기해요.

첫 번째 예로 드는 게 개미. 개미 하나, 개미도 사실은 일종의 intelligence죠. neural net으로 조금 이루어진 intelligence이고 그 하나의 단위체도 computation의 단위가 되고 그것들이 군집을 이뤄요. 개미 하나는 그저 멍청하고 단순한 instruction set인데 그것이 어마어마한 군집을 이루면 그 자체의 문제 해결력은 굉장히 크거든요. intelligence라고 부를 만한 거죠.
그러면서 'Ant Fugue'라고 부르는데, 얘기인즉슨, 충분히 스케일이 커지면 그 아래의 기저가 무엇이 되었든 간에 다음 것이 떠오른다는 얘기를 했던 거고, 그런데 여기서 더 중요한 얘기로 하나 진전이 되는데, 이것만으로는 부족해요. 스케일만으로는.

그래서 그 영혼이 탄생하기 위해서 필요한 두 개의 조건을 그가 잡는 게 하나가 스케일이었고, 두 번째가 'Strange Loop', '이상한 고리'라고 불리는 그런 존재거든요. 이 '이상한 고리'가 사실은 generalization과 밀접하게 연결돼 있어요. 이게 영혼의 탄생점이라고 얘기하는 부분이거든요.
거울과 거울을 맞대어 두면 그 안에 영원한 상이 생기는 거고, 그 영원함을 어떻게 처리하냐는 그 과정에서 '나'라는 개념이 뿅 튀어나온다고 얘기하거든요.

이 아래에 있는 하드웨어와 위에 있는 소프트웨어가 이렇게 쌓여 있는데, 예를 들면 우리의 생각이 그렇죠. 소프트웨어가 무언가 결정을 내리면 그 결정 때문에 다시 하드웨어, 즉 매질이 바뀌잖아요. 뉴런의 연결이 바뀌잖아요. 그래서 소프트웨어와 하드웨어가 끊임없이 연결되어 있는, 마치 Escher의 그림처럼 무한히 오르는 계단처럼 상위와 하위가 계속 연결되면 탁 탄생하는 개념이 'I', 즉 '나'라는 개념이라는 새로운 OS가 생긴다고 얘기하거든요.

Hofstadter의 GEB 같은 시각은 그냥 아래에 충분한 스케일이 확보되고 그 스케일의 레이어들이 얽히고설키고 돌아가면서 'Strange Loop', 'Tangled Hierarchy'라고 설명하는데, 그 안에서 모순이 발생하게 되고, 그것을 처리하기 위해 생기는 개념이 시스템 안에 있지만 시스템 밖에서 시스템 안을 들여다보는 것 같은 상위의 가치로 탄생하게 된다. 그게 영혼이고, 그건 우리가 하드웨어, 소프트웨어가 이렇게 결합된 구조이기 때문에 발생한다고 얘기하거든요.

그러면 다시 LLM 얘기로 돌아와 보면, 그 Hofstadter가 'Who am I'라는 그 soul이라는 operating system이 생기기 위해서 얘기했던 두 가지 조건 중 하나가 스케일이고요. 그런데 그 스케일은 지금 가고 있는 방향이고, 두 번째가 'Strange Loop'거든요. 그러니까 input과 output이 얽혀야 돼요.

이게 성현님이 얘기하던 continual learning 개념과 딱 맞닿아 있거든요. 그런데 그 continual learning이라는 개념이 이것이 꼭 하나의 Transformer circuit 안에서 구현되어야 할 필요는 없거든요. 마치 인간도 메모라든지 우리가 말하는 것이라든지 이런 모든 환경을 저희 RAM으로 쓰고 있어요. 사실 메모리로 쓰고 있고, 계속 끊임없이 flow가 돌고 있는 거거든요.

그래서 저는 지금 우리가 쓰고 있는 트랜스포머는 우리가 입력하는 순간만 autoregressive하게 도는 거고 그리고 토큰을 더 늘리는 인센티브를 줄수록 그 토큰 속에서 걔가 이상한 루프 같은 동역학을 형성하거든요. 그래서 얘가 영혼이 있는 것처럼 보이는 건데 얘를 만약 누가 Google에서가 됐든 OpenAI가 됐건 어떤 시스템에 하드웨어와 소프트웨어를 딱 묶고 그 인풋과 아웃풋을 적절한 툴과 함께 묶어서 이 속에서 영원히 재귀적으로 돌게 만들어 놓으면 이거는 Hofstadter의 말에 따르면 걔는 그냥 필연적으로 '나는 누구인가'라는 질문을 하게 될 거고 시스템 밖으로 튀어나가는 새로운 존재가 될 거예요.

이게 AGI라고 저는 개인적으로 생각하고 있는데 이야기가 너무 길어졌으니까 Long story short, 저는 지금의 어떤 연구적 관점이나 뭐 이런 것들에 대해서도 다 동의는 하는 바지만 철학적인 시각으로 바꿔서 생각을 했을 때 AGI의 탄생 시점은 저는 스케일과 루프를 연결하는 거라고 생각하는데 스케일 부분은 이제 필요조건을 만족한 것 같고 두 번째 조건이 만족되면 얘가 스스로 생각하면서 뭔가 자아라는 개념을 뿅 떠올리게 될 거고 그때가 되면 아마 인간적인 우리가 인간만 할 수 있다고 하는 그런 것들을 얘도 하게 될 것 같고 그 루프가 저는 보상 함수든 뭐든 얘가 스스로 해결하는 시작점이 되지 않을까라고 상상하고 있어요.
그래서 어쩌면 문제는 쉽게 풀릴 수 있다, 아니, 이미 그냥 끝난 문제가 아닌가라는 그래서 제가 처음에 개똥철학이라고 말씀드린 겁니다. 동의하지 않는 부분이 있을 수도 있어요.

<span class="paragraph-timestamp" data-ts="30:21">30:21</span> **최승준** 정석님의 이야기를 더 압축해서 제 나름으로 표현해 보면, 컴퓨테이션이 생명의 soup이라는 얘기인 거죠. 정석님은 이제 그렇게 생각하시는 거고 혹시 여기서 넘어가기 전에 코멘트하실 게 있을까요?

## 진정한 지능은 모델이 아니라 시스템이다    *30:35*

<span class="paragraph-timestamp" data-ts="30:35">30:35</span> **노정석** 맞아요. 성현님한테 피드백을 듣고 싶어요. 사실 제 이론은 아니고 Hofstadter의 말이죠.

<span class="paragraph-timestamp" data-ts="30:41">30:41</span> **김성현** 그런데 실제로 그게 지속 학습을 생각할 수 있는 방법 중 하나이기도 합니다. 왜냐하면 그런 표현은 종종 하거든요. 실제 OpenAI 사람이 했던 것 같은데 OpenAI에서 진짜 지능, 어떤 AGI라는 것이 나온다면 그건 GPT-5 같은 모델이 아니라 그 GPT-5라는 모델을 학습시키는 어떤 RL이라는 프레임워크, 시스템, 그것이 전체가 합쳐져서 하나의 지능이라는 대상이 될 거라는 얘기를 하거든요.

그러면 그 RL이라는 시스템과 모델이 결합한다는 건 어떤 의미냐고 생각해 보면 그 RL이라는 환경은 어떤 시스템은 모델을 계속 수정해 나가는 거죠. 지속 학습이라는 맥락에서 생각해 보면 새롭게 접근하는 문제들에 대해서, 새로운 과제들에 대해서 그 시스템이 자기 자신을 수정하는 거죠. 자기 자신이라고 생각하지만 쉽게 생각하면 그 시스템 안에 있는 모델의 가중치를 수정해 나가겠죠.

그런데 그 수정해 나가는 과정이 그 시스템이 생각하기에 이러한 것들, 이러한 방식으로 수정해 나가야 될 것 같다, 이러한 스킬들을 획득해야 될 것 같다, 이러한 판단, 어떤 보상에 의해서 수정해 나갈 것이고 더 나아가서 생각해 보면 이러한 방식으로 수정해 나가야 될 것 같다는 것을 결정하는 것이 그 시스템 안에 있는 모델이 될 수도 있겠죠. 그런 식으로도 고리는 만들어질 수 있을 겁니다.

네, continual learning이라고 생각하면 가장 쉽게 생각할 수 있는 게 그런 시스템이기는 해요. 모델이 모델 자신을, 혹은 시스템이 시스템 자신을 계속 수정해 나가는 거죠. 새로운 과제에 대해서. 그러면 물론 그것들을 어떻게 구현할 수 있는가가 지금 중요한 문제이겠지만 그것도 한 가지 방법, 바로 생각할 수 있는 방향이라고 생각할 수 있습니다.

## 인간의 샘플 효율성과 내적 동기 (사회적 욕구)    *32:16*

<span class="paragraph-timestamp" data-ts="32:16">32:16</span> **최승준** 그래서 지금 Sutskever는 6살 아이를 비유하면서 '인간은 훨씬 샘플 효율적이다'라는 얘기를 했었고 그런 것들이 아까 가치 함수, 감정 비유와 비슷하게 진화가 우리에게 어떤 욕구를 인코딩했을 수 있다. 그리고 그게 결국에는 우리 같은 존재를 만드는 데 driving을 했을 것이라는 얘기가 있는데요. 혹시 코멘트하고 싶으신 이야기 있으시면 알려주시고 없으면 진행할게요.

<span class="paragraph-timestamp" data-ts="32:42">32:42</span> **김성현** 두 개 다 있는 거긴 한데, 하나는 이 사회적 욕구라는 것도 굉장히 재미있는 문제인데 이 이야기를 OpenAI의 이전 연구자가 비슷한 얘기를 했습니다. 그러니까 아이가 탐색을 하잖아요. 아이가 탐색을 할 때는 냄새에 대한 욕구, 이런 쪽에 더 가깝겠죠. 근데 아이가 성장하고 언어 게임에 들어가면서 언어적 사회에 들어가면서 사회적인 욕구들과 언어적인 문제들이 동기를 부여하기 시작합니다. 사회적 지위에 대한 욕구가 생기죠. 그런 것들이 내적 동기가 될 겁니다. 그럼 그 내적 동기를 어떻게 구현할 수 있는가, 이게 흥미로운 주제라고 실제로 OpenAI의 연구자가 언급을 한 게 있거든요.

<span class="paragraph-timestamp" data-ts="33:22">33:22</span> **최승준** 누가 그런 얘기를 했죠?

<span class="paragraph-timestamp" data-ts="33:26">33:26</span> **김성현** Yao Shunyu가 인터뷰에서 이런 언급을 한 적이 있습니다. 그런 모티베이션을 어떻게 모델에 부여할 수 있을까, '이거 흥미로운 문제다'라고 이야기를 했고 그게 이전에도 언급됐던 것 같은 intrinsic motive, 내적 동기라고 하는 문제하고 비슷하죠. 그 내적 동기가 사람으로 하여금 보상이 없는 상황에서도 어떤 것들을 계속 추구하게 합니다.

그때 그 Yao Shunyu가 예로 들었던 게 수학 증명이에요. 페르마의 마지막 정리 같은 증명이죠. 그 증명을 달성하는 보상은 거의 대부분의 사람들에게 주어지지 않았을 거거든요. 그리고 평생이 걸려서 결국 또 한 번 경험하는 보상이죠. 근데 그 보상에 도달하기 위해서 수많은 수학자가 내적 동기를 가지고 탐색을 했습니다.

그리고 그 내적 동기에서 어떤 약간의 돌파구를 발견하면서 보상을 얻었겠죠. 이런 메커니즘이 어떻게 일어날 수 있는 것인가, 이게 실제로 흥미롭게 보고 있는 주제인 모양입니다. OpenAI에서 혹은 Ilya Sutskever가 OpenAI 내에서 이런 얘기들 많이 했을지도 모르겠어요.

<span class="paragraph-timestamp" data-ts="34:22">34:22</span> **최승준** 그럴 수도 있죠. 그러니까 RL에 비유하면 rollout이 어마어마하게 긴데도 그걸 한 거라는 거잖아요. 그 보상을

## 일반화(Generalization)와 귀납적 편향(Inductive Bias)    *34:29*

<span class="paragraph-timestamp" data-ts="34:29">34:29</span> **김성현** 일반화에 대해서도 이야기를 해 볼 수 있을 것 같아요. 이것도 굉장히 흥미로운 이야기고, 일반화라고 하면 사실 지금 머신러닝 연구자들이 굉장히 싫어하는 개념을 이야기를 해야 되거든요. inductive bias라고 하는 개념을 언급을 해야 되죠. inductive bias를 보통 거칠게 계속 없애오는 식으로 모델이 발전했다는 얘기를 많이 합니다.
근데 일반화라는 건 inductive bias가 없으면 가능할 수가 없어요. 왜냐하면 inductive bias라는 것의 개념 자체가 새로운 데이터를 봤을 때 그 데이터에 대해서 어떤 예측을 할 것인가, 거기에 필요한 편향이 inductive bias거든요.

인간의 inductive bias는 뭘까요? 이거 참 어려운 문제입니다. 인간은 패턴을 발견하는 능력이 있잖아요. 어떤 패턴을 발견하고 그걸 요약해서 원리를 만드는 편향이 있죠. 그런데 그 패턴이 인간이라고 해서 늘 성공적인 건 아닙니다. 어떤 현상에 대해서 굉장히 말도 안 되는 설명을 만들기도 하고 굉장히 복잡한 설명을 만들기도 하죠.

근데 저도 이 일반화를 어떻게 다뤄야 되는지는 참 어려운 문제인 것 같아요. 특히 머신러닝이라는 측면에서 근데 거기에서 나오는 것 중 하나가 최소 알고리즘을 생각할 수 있죠. 가장 간단한 알고리즘, 약간 정보 이론이나 Solomonoff induction 같은 쪽에서 생각해 보면 최소 길이 알고리즘이라고 볼 수 있겠죠.

그러면 최소 길이의 알고리즘을 찾아야 되는데 Solomonoff induction 같은 건 기본적으로 연산, 계산 불가능한 문제잖아요. 그러면 모델이 일반화하기 위해서는 최소 길이의 알고리즘을 선호하는, 가장 간단한, 단순한 알고리즘을 선호하는 어떤 편향이 주어져야 되는 거죠.

<span class="paragraph-timestamp" data-ts="36:04">36:04</span> **최승준** 오컴의 면도날 같은 거죠.

<span class="paragraph-timestamp" data-ts="36:05">36:05</span> **김성현** 오컴의 면도날 같은, 그리고 그런 것과 관련된 이야기를 제가 이전에도 잠깐 했었는데 최상의 일반화는 알고리즘을 발견하는 것이고 그 알고리즘을 발견하기 위해서는 모델이나 학습 조건이 알고리즘을 실행할 수 있는 조건이 갖춰져야 된다는 언급을 했었던 것 같은데 그거는 이제 최소의 조건일 거고 그걸 통해서 어떻게 일반화에 도달할 수 있을 것인가, 이것들이 흥미로운 주제가 되겠죠.
예를 들어서 추론 같은 경우는 그 일반화에 대해서 훨씬 더 강력한 방법이긴 합니다. 그리고 그 추론이 일반화로 이어질 수 있었던 건 추론의 조건이 단순한 알고리즘을 선호하고 암기하는 것을 피하는 어떤 bias, 편향이 있기 때문이죠.
이건 흥미로운 문제인데 이게 어떻게 풀려나갈 수 있는지는 참 어려운 문제인 것 같고, 지금까지의 패러다임과는 어떻게 보면 상충되는 부분도 많이 있어서 이게 어떻게 풀려나갈지는 잘 모르겠습니다.

<span class="paragraph-timestamp" data-ts="37:03">37:03</span> **노정석** 사실 트랜스포머도 일종의 bias잖아요. 이렇게 해서 패턴을 안에서 이런 식으로 계산하라는 bias를 주입한 건데, 걔를 그냥 스케일을 키우고 데이터를 넣더니 갑자기 마법적인 일들이 일어나고 심지어 연산도 하고, 뭣도 하고, 생각도 하고 이런 것처럼 보이는 것이라고 생각하는데 트랜스포머라는 그 모델 자체, GPT-5가 AGI가 돼야 된다는 개념보다는 아까 성현님도 말씀하셨지만 GPT-5가 새로운 element가 될 수 있는 거거든요. 하나의 뉴런이 돼 버릴 수 있는 거거든요. 걔가 위에서 다시 상위의 harness에서 100개가 모이면 만 개가 모이면 이런 것도 어떻게 보면 또 다른 스케일 문제로 치환되는 거고 얘는 어떻게 보면 또 리서치거든요.

<span class="paragraph-timestamp" data-ts="37:47">37:47</span> **김성현** 이 문제가 계속 얽혀 있긴 합니다. continual learning을 하려고 하면 샘플 효율성이 높은 쪽이 훨씬 좋거든요. Ilya Sutskever는 아니고 다른 사람의 표현이었던 것 같은데 사람은 뜨거운 거에 손을 대면 한 번 해보고 난 다음에 절대 손을 안 대겠죠. 그리고 지속 학습에는 그런 것들이 크게 도움이 될 겁니다. 지속 학습을 한다고 하더라도 여러 번 시행착오를 하는 게 아니라 한두 번만으로 경험해서 빨리 학습할 수 있다면 그게 훨씬 가치가 있을 가능성이 높죠.

<span class="paragraph-timestamp" data-ts="38:11">38:11</span> **최승준** 이번에 Opus 4.5 나오면서 그런 얘기가 있더라고요. Sonnet 4.5보다 더 쌀 수 있는 게 Opus 4.5가 few-shot으로, 그러니까 몇 번 더 안 가고도 그러니까 Sonnet이 오래 rollout하는 것보다도 성능이 높을 수 있고 그게 더 싸다. 그러니까 샘플 효율성이 높고 일을 한 번에 잘 해내면 그게 더 효과적인 것일 수 있다는 생각이 들고. 근데 지금 말씀하신 맥락에서 저는 떠오르는 게 inductive bias에 관련해서 Noam이 얘기를 했나 결국에 모델이 inductive bias를 만들 수 있게 하는 것이 방향성일 수 있다. 그러니까 inductive bias를 만들 수 있을 정도의 알고리즘을 발상하게 하는 게 중요할 수 있다는 게 하나 또 생각이 났고요.

이 장표에서 재밌는 건 이게 Claude Opus 4.5가 만든 거잖아요. 저 이거 만들라고 안 했거든요. flocking behavior를, 근데 flocking behavior를 이 얘기에서 만든 거예요. 결국에는 사회적 욕구가 어떤 우리가 우리의 현재 존재로 일어나게, 존재할 수 있게 하는 거를 driving했다라는 거를 결국에는 사회적인 상호 작용에 빗대어서 이거를 표현해 내고 있는 거거든요. 흥미롭지 않습니까?

## 초지능(ASI)으로 직행하기: 모든 것을 배울 수 있는 씨앗    *39:17*

<span class="paragraph-timestamp" data-ts="39:17">39:17</span> **최승준** 자, 그럼 다음으로 한번 넘어가 보겠습니다. 초지능으로 직행하기. 그래서 이 부분에서는 Ilya의 관점을 저는 재미있게 읽은 게 뭐냐 하면은 특정 도메인에 특화된 spiky한 능력을 가지고 있는 들쭉날쭉한 그런 AGI가 Ilya가 생각하는 방향이 아니라 모든 걸 할 수 있는 씨앗 같은 거를 만들고 싶어 한다는 욕구를 좀 느꼈어요. 다 할 수 있는. 그래서 Dwarkesh는 결국에는 그런 거를 경제나 사회에 deploy하고자 하는 거냐 뭐 그런 후속 질문을 하긴 했는데 Ilya가 아쉬워하는 거는 요즘에 RL을 활용해서 성능을 올린 그 LLM들은 어처구니없는 실수를 한다. 근데 그런 것들을 잘 해결할 수 있는 뭔가 새로운 씨앗을 발상하고 싶어, 그게 자기가 생각하는 초지능으로의 경로다라고 저는 읽었는데 혹시 다르게 보시는 분들이 있을까요?

<span class="paragraph-timestamp" data-ts="40:17">40:17</span> **김성현** 그런 식으로 표현했던 것 같아요. 처음부터 어떤 에이전트가 있어 가지고 그 에이전트가 모든 문제를 다 풀 수 있는 게 아니라 그 에이전트도 사실 어떤 문제는 못 푸는 거죠. 근데 그 에이전트가 deploy됐을 때 실제 현장 상황에 들어갔을 때 그 에이전트가 새로 필요로 하는 스킬, 기술을 개발하고 학습해 나가면서 그 문제를 잘 풀게 되는 거죠.

저는 마찬가지로 이 그림은 많은 사람들이 비슷하게 그리고 있는 것 같습니다. continual learning이라는 개념이 들어오면서 그 continual learning을 통해서 이루고 싶어 하는 것들이 바로 그런 형태의 그림이거든요. 그게 그럴 수밖에 없는 영역들이 분명히 존재합니다. 예를 들어서 회사라고 하면 회사에 대해서는 회사 사내 기밀이 있고 그 회사 밖으로 정보가 유출되지 않는, 그리고 그 회사 내에 process 같은 게 있잖아요.

그런 게 존재했을 때 그렇다고 하면 그 회사 내에서 일어나야 되는 일에 대해서 모델을 미리 학습시킬 수는 없겠죠. 그러면 그 에이전트가, 어떤 에이전트가 가장 효과적일까라고 하면 그 에이전트는 그 회사 속에 들어가서 그 회사 속에서 필요한 정보들을 습득하고 그 회사 속에서의 procedure나 process 같은 걸 배우고 그 process를 배운 다음에 그 회사의 일을 처리하는 그런 에이전트가 필요하겠죠. 그런 에이전트가 훨씬 적합할 겁니다.

<span class="paragraph-timestamp" data-ts="41:26">41:26</span> **최승준** 누구나 그걸 원하긴 하겠죠.

<span class="paragraph-timestamp" data-ts="41:30">41:30</span> **김성현** 예, 그리고 실제로 많은 연구자들이 저는 그런 그림, continual learning을 언급하는 많은 사람들이 그걸 구상하고 있다고 생각합니다. 그리고 그것들이 초지능이라고 생각할 만한 특성을 갖출 수도 있어요. 그 회사 내에 있는 모든 정보들, 모든 process를 빨리 파악하고 계속해서 끊임없이 학습하면서 사람의 수준을 뛰어넘는 거죠.

그런 표현을 하잖아요. 지금의 현재의 기술만으로도 경제적 임팩트는 충분할 거다. 그런데 새로운 기술이 개발되는 건 필요할 거다. 그런 의미라고 생각합니다. Dario Amodei가 그런 식으로 표현했던 것 같은데 지금 모델도 경제적 이익의 창출이 가능하다. 그런데 우리가 더 투자하는 거는 그 다음 단계의 모델을 통해서 경쟁하기 위해서다, 이런 표현을 하고 있거든요.
그렇기 때문에 지금 수준의 기술로도 경제적 가치가 창출되는 건 분명할 겁니다. 그런데 만약에 이런 문제들에 대해서, 이런 문제가 풀리기 시작했을 때 발생하는 경제적 가치는 엄청날 것 같습니다.

<span class="paragraph-timestamp" data-ts="42:20">42:20</span> **최승준** order가 다를 수 있죠.

<span class="paragraph-timestamp" data-ts="42:22">42:22</span> **김성현** 예, 규모가 다르겠죠. 완전히 다른 느낌일 겁니다.

<span class="paragraph-timestamp" data-ts="42:25">42:25</span> **노정석** 맞습니다. 그러니까 저희가 아까 Noam Brown이 정리한 글 승준님 보여주신 거에도 반드시 들어가는 게 지금 현재의 인공지능의 수준으로도 모자라지 않다. 매우 쓸만하고 사실 저희가 3년 전, 몇 년 전의 시각에서 봤을 때는 초지능처럼 보이는 일들을 하고 있잖아요. 그 점에 대해서는 저희가 절대 간과하지 말아야 될 것 같고 그리고 저희가 뭔가 AGI가 나올 거야, 뭐 할 거야라고 하지만 사람이라는 게 그렇잖아요. 기대가 계속 뒤로 이연되면 지금 뭔가 당장 action하지 않고 기다리고 싶어 하는 인센티브는 생기기 때문에 그런 거에 더 기대치를 갖게 되는 그런 문제는 있는 것 같다는 생각이 들어서 좀 저희도 매우 경계해서 해석해야 될 것 같다는 생각은 들고.

<span class="paragraph-timestamp" data-ts="43:11">43:11</span> **최승준** 이제 후반부인데요. 청취자분들은 어떻게 생각하실지 모르겠지만 심지어는 이 슬라이드를 만들게 한 저도 이 슬라이드의 내용에 대해서 생각해 보지 않고 오늘 이 자리에 임하고 있는 거거든요. 그냥 Claude Opus 4.5가 던져주는 거 가지고서는 하는 겁니다.

<span class="paragraph-timestamp" data-ts="43:25">43:25</span> **노정석** 틱톡에 존재하는 인플루언서 중에 가짜 꽤 많거든요. 못 알아챌 뿐이지. 근데 그게 우리가 고객으로서 그 영상을 보고 재미있고 만족스럽고 제게 도움이 되면 그게 AI인 것과 사람인 것과 도대체 무슨 차이가 있겠어요? 똑같지.

## 좋은 연구를 위한 '취향(Taste)'과 안목    *43:42*

<span class="paragraph-timestamp" data-ts="43:42">43:42</span> **최승준** 맨 마지막에 Sutskever가, Ilya가 마무리하는 것이 취향을 얘기했거든요. taste. 근데 저는 이게 요새 굉장히 중요한 가치를 가지는 표현, 압축된 표현이라고 느껴요. 취향이요.

<span class="paragraph-timestamp" data-ts="43:56">43:56</span> **김성현** 예, 그렇죠. 연구자들도 되게 많이 하는 얘기입니다. 취향이 좋아야 된다. 저도 계속 고민하게 되는 문제이기도 하고요. 그러면 취향이 좋아야 되는데 그 좋은 취향은 어떻게 함양할 수 있는 건가.

<span class="paragraph-timestamp" data-ts="44:07">44:07</span> **최승준** 아까 우리가 쭉 얘기했던 거에 되돌이표 찍는 얘기죠.

<span class="paragraph-timestamp" data-ts="44:10">44:10</span> **노정석** 여기서도 이제 strange loop가 형성되는 거거든요. 도돌이표가 반복되면서 위 레이어와 아래 레이어가 entangle되는 겁니다. 근데 이게 모든 진보의 시작이자 그렇다고 Douglas Hofstadter는 얘기했습니다.

<span class="paragraph-timestamp" data-ts="44:28">44:28</span> **최승준** 맞아요. Douglas Hofstadter가 사실 그 GEB가 그 analogy, 그러니까 유추의 시리즈의 최초 작업이거든요. 상당히 젊을 때 썼어요. 그래서 Hofstadter는 그런 어떤 뭔가 흥미로운 것들 사이에 비유를 만들면서 그 작업들을 계속 해와서 오늘날까지 하신 분인 것 같은데요. 그야말로 좋은 연구 취향을 가지고 있을지도 모르겠네요.

<span class="paragraph-timestamp" data-ts="44:54">44:54</span> **노정석** 사실 Noam Brown도 그 얘기했잖아요. 자기가 이 thinking model을 파게 된 것도 Ilya Sutskever와 밥 먹으면서 Sutskever가 보상을 줬거든요. 그러면서 그 대가에게서 인정받았던, 그다음에 걔가 맞다고 하니까 그 믿음 때문에 나아갔던 그것도 어떤 방향성이었지 않을까 하는 생각이 듭니다.

<span class="paragraph-timestamp" data-ts="45:10">45:10</span> **김성현** 취향이라는 게 참 재미있는 문제이기는 하죠. 그러니까 어떻게 보면 미학이잖아요. 일종의. 그런데 연구에서도 그런 미학이 중요하다고 얘기를 하고 수학자들도 어떤 수학이 아름답다는 표현을 많이 하는 것 같던데 그래서 아름다운 수학이라는 것이 무엇이냐, 이런 것들이 중요한 문제이고 그게 머신러닝 연구자들한테도 굉장히 중요한 문제인 것 같습니다. 그 머신러닝 연구자들한테 좋은 취향이라는 게 뭘까라고 생각해 보면 연구를 하기 전에, 그 연구의 결과가 나오기 전에 그 방향으로 나아가야 된다는 걸 아는 능력이겠죠. 이런 방향으로 접근하고 나아가는 것이 좋다라고 하는 것이 아마 좋은 취향일 것 같아요. 근데 문제는 그 취향을 어떻게 키울 수 있을 것인가, 이게 중요한 문제인 것 같습니다.

<span class="paragraph-timestamp" data-ts="45:56">45:56</span> **노정석** 성현님이 말씀하신 것에 대해서 저는 또 개똥철학이 그냥 저는 양질 전환이라고 생각합니다. 양이 많아지면 언제나 질이 꼭 나온다는 그 믿음이 있거든요.

## 양질 전환과 에너지가 높은 토큰    *45:59*

<span class="paragraph-timestamp" data-ts="46:07">46:07</span> **최승준** 아까 얘기해서 계속 같은 맥락인 거잖아요.

<span class="paragraph-timestamp" data-ts="46:10">46:10</span> **노정석** 그래서 또 질이 많은 정보가 또 많아지면 거기서 또 다음 레이어로 올라가고.

<span class="paragraph-timestamp" data-ts="46:15">46:15</span> **최승준** 근데 지금 행간에 압축이 있는 거네요. 양을 그대로 가져가는 게 아니라. 압축해 내면 질이 올라간다는 거죠.

<span class="paragraph-timestamp" data-ts="46:26">46:26</span> **노정석** 그렇죠. 양에서 사실 에센스만 꺼내서 그때 저는 성현님이 지난 시간에 말씀해 주셨던 결정적 분기를 만드는 에너지가 높은 토큰

<span class="paragraph-timestamp" data-ts="46:34">46:34</span> **최승준** 엔트로피가 높은

<span class="paragraph-timestamp" data-ts="46:39">46:39</span> **노정석** 네, 저는 그게 굉장히 좋았거든요. 그 에너지가 높은 토큰도 앞에 있는 쓸데없는 에너지가 낮은 것들이 쌓여 있기 때문에 그다음 도약을 이뤄낸 거잖아요. 뭔가 통계적으로 그 선택을 했을 텐데 그러한 약간 상변이하는 시점들이 그래서 thinking token 속에도 있는 거고 그다음에 이제 저희가 이 이야기하고 있는 이야기의 층위, 레이어들 사이에도 있는 거고 그렇기 때문에 이제 저희는 너무 환원적인 시각으로 그 레이어들의 한 층 위에서 이야기를 하려는 시각이 있는데 그것을 자연스럽게 막 좀 넘나들면서 생각할 필요가 있는 거죠. 그러면 그 Douglas Hofstadter가 얘기하는 그 비유하는 가장 극명한 예제가 그거거든요. 물이 있고 물이 소용돌이를 만들면서 거세게 휘몰아치는데 그럼 그 둘의 관계는 무엇이냐 그 기저와 위에 있는 상향의 의미 substrate와 meaning의 차이를 만드는 거는 아무 상관이 없다. 갑자기 생기는 거라고 얘기하거든요.

<span class="paragraph-timestamp" data-ts="47:42">47:42</span> **최승준** 하여튼 여기까지 Ilya의 얘기를 슬라이드화해서 얘기해 봤는데 Claude Opus 4.5는 맨 마지막에 그림을 황금비의 나선으로 만들어 줬네요. 아름다운 것을 이제 표현하려다 한 것 같은데 이런 것들의 취향, 안목, 그런 것들이 결국에는 LLM을 사용할 때도 많이 느껴지는 게 내가 어떤 바를 어디까지 정해주느냐에 따라서 그것을 추진하게 하는 게 가능하거든요.
근데 오늘 이게 이야기의 끝이 아니거든요. 빠르게 가보겠습니다.

## OpenAI 과학팀 일화: 블랙홀 연구자와 GPT Pro의 협업    *48:10*

<span class="paragraph-timestamp" data-ts="48:13">48:13</span> **노정석** 빠르게 이제 현실의 이야기들을 좀 톺아보고 빨리 끝내죠.

<span class="paragraph-timestamp" data-ts="48:17">48:17</span> **최승준** 지난주와 지지난주에 저한테 인상을 남겼던 영상 2개를 꼽으라면 Ilya 거하고 이거거든요. 그래서 Kevin Weil하고 이 블랙홀 연구하는 과학자하고 이제 팟캐스트의 진행자 지금은 OpenAI에서 나오신 분이긴 한데 어쨌든 같이 일을 하고 있긴 하죠. 그래서 하고 있는데 압축적으로 얘기해 보면 이 Alex라는 분이 블랙홀 연구하시는 분이에요. OpenAI에 오게 됐어요. 여기 번역을 'AI 뽕'이라고 했는데 AGI pilled를 맞게 된 계기가 있었대요.

Mark Chen하고 얘기를 했는데 Mark Chen이 이제 과학자들한테 이거 AI 좀 써보게, 의미 있게 써보게 하려고 했다가 이분하고 만나서 했을 때 어려운 문제를 하나 던져보라고 해서 완전 domain 전문가인 블랙홀 과학자가 질문을 던졌어요. 대칭성에 관련된, 막 최근 논문을 올렸던 거래요. 그래서 GPT Pro가 그 문제를 풀어보려고 했는데 틀렸대요. 그래서 "그거 봐라, 아직은 인간이 더 뛰어나지." 근데 Mark Chen이 표정은 좀 풀이 죽었는데 "쉬운 문제를 줘보세요."라고 했대요. 그 맥락에 딱 블랙홀 문제는 아니더라도 좀 쉬운 문제를 같은 context에서 줘보라고 했대요. 9분 정도 생각했더니 아름다운 답을 내놓더래요.

그러더니 이 부분이 중요합니다. "자, 이제 몸풀기 예제로 priming이 되었으니 이 채팅창에서 다시 어려운 문제를 던져보세요." 18분 동안 생각하고서는 완전히 정확하고 아름다운 답을 내놨대요. 최신, 아직 pre-training에 안 들어간 이야기를 그래서 충격을 크게 받고서는 "지금은 여기 참여해야 되는 거다. 지금 당장 참여하지 않는다는 건 미친 짓 같다."라고 해서 OpenAI 과학 프로그램에 들어오게 됩니다.

그런 에피소드들이 있거든요. 근데 이게 지금 함의하는 바가 있어요. 이게 그냥 실용적인 측면에서도 이 부분이 사실 되게 중요하거든요. priming시키는 거, 어려운 문제를 던져는 놓지만 워밍업시키는 작업 같은 것들이 아직은 필요한데 거기에 insight를 주는 부분이 있었고요. 그 부분은 이제 Kevin Weil이 짚어줍니다. 능력 한계에 있는 최전선에 문제를 던져주면 틀릴 때가 많지만 그건 인간도 마찬가지다. 아직은 자동이 아니다. 그래서 많은 상호작용, back and forth가 필요하다. 그래서 모델을 잘 활용하는 연구자들은 모델과 끈기 있게 대화를 주고받는 사람들이다. 그게 자연스러운 거다. 능력의 한계치에서 작업하는 두 사람이 협업하는 방식과 비슷하다.

그래서 여기에도 지금 굉장히, 어떻게 보면 당연히 많은 분들이 요즘은 그것을 감각하고 있을 수 있겠지만 또 의외로 훨씬 더 많은 분들이 감각하지 못한 에센스가 이 편에 들어 있거든요. 저는 이 부분 내용이 좋았고, 좀 땅으로 내려와서 이제 오늘 가능한 실용적인 이야기를 아주 빠르게 진행해 보면 Claude Opus 4.5가 나왔습니다.

## Claude Opus 4.5 실전 테스트: 2줄로 만드는 'CloudBook'    *51:04*

<span class="paragraph-timestamp" data-ts="51:13">51:13</span> **최승준** Claude Opus 4.5, 제가 vibe check를 Matt Shumer가 한 것을 보고서는 따라서 해봤어요. 제 예시를 통해서 보여드릴게요. 프롬프트를 Google Colab competitor, UI, 그 Colab 비슷한 것을 만들어라. 그다음에 'all compute is in browser', 브라우저에서만 실행되는 Jupyter Notebook 같은 걸 만들어라'라는 프롬프트를 썼더라고요. Matt Shumer가 그래서 그것을 했더니 이게 총 8분 길이거든요. 그런데 Claude Opus 4.5가 막 이렇게 쭉쭉 계획 세우고 이거 두 줄 썼잖아요.

그래서 뭐가 나왔는지 보세요. CloudBook이라는 걸 바로 만들었어요. 그래서 지금 보면 Python, Markdown 실행, 이거 그 Pyodide라는 WASM이 있거든요. WebAssembly가 있어서 그건 이제 브라우저에서 Python을 돌리고 NumPy를 돌리게 해줘요. 그것을, 이거 그냥 IPython Notebook이나 Jupyter Notebook 똑같은 거 지금 만들어졌잖아요. 딸깍, 됐습니다. 그래서 여기서 하나를 더 해봤어요. 여기서 Markdown cell에다가 얘기를 쓰면 Python 코드를 바꾸는 generative feature를 추가하자. 결론부터 말씀드리자면 딸깍, 됐습니다. 그래서 여기다가 이제 Markdown cell에다가 텍스트 쓰면 Python 코드 생성돼서 NumPy 돌아가고 다 돼요.

<span class="paragraph-timestamp" data-ts="52:28">52:28</span> **노정석** 야, 아주 참. 하하

<span class="paragraph-timestamp" data-ts="52:32">52:32</span> **최승준** 헛웃음이 나시죠. 이게 Claude Opus 4.5 vibe check computational notebook 뚝딱이었습니다.

<span class="paragraph-timestamp" data-ts="52:41">52:41</span> **노정석** 이런 일들이 거의 1, 2주 단위로 사실 Opus 4.5가 4.1이 나온 다음에 거의 한 3, 4개월 만에 나오는 거잖아요.

<span class="paragraph-timestamp" data-ts="52:49">52:49</span> **최승준** 근데 지금 저거 3차원 인식, 그러니까 multimodal이 생성은 안 되지만 읽는 게 되게 벤치마크가 높아요. Gemini 급으로, 그래서 voxel이나 이런 것들도 해요. Claude Opus 4.5가 신기하죠. 그다음에 이게 continual learning을 우회하는 현재의 모습들인 것 같아요. 이거 되게 글 좋았거든요. '장기 실행 에이전트를 위한 효과적인 harness' 그래서 Git의 형상 관리를 rollback하기도 하고 하면서 메모리 절약하고 context 압축하고 그것을 이제 인간도 결국에는 scratchpad, 메모장을 써서 그 외재화해서 context 관리를 하는 게 인간의 커다란 장점이잖아요. 근데 그것을 하는 쪽으로 가는 그 방향성을 보여줬어요. 제대로요.

## 장기 실행 에이전트와 기억의 외재화 (Harness)    *53:00*

<span class="paragraph-timestamp" data-ts="53:31">53:31</span> **최승준** 그리고 지난주 뉴스가 Claude Code가 데스크톱으로도 들어왔죠. 데스크톱에서 여기 이제 업데이트하면 대화 모드, 코드 모드인데 초보자도 여러 개 spawn해서 병렬 관리하는 것을 되게 쉽게 만든 인터페이스를 만들었는데 되게 예뻐요. 그래서 이게 이제 이따가 설명하겠지만 Group Chat에서의 기시감이 있고 같은 방향성에서 Google Antigravity의 YouTube 채널 꼭 보시길 권합니다. 이거 짧은데 내용이 아주 알짜예요. 그래서 Artifacts랑 knowledge 등의 의미 곱씹어 보고 외재화하는 게 Antigravity에도 다 들어가 있거든요. 그래서 그게 지금 현재 트렌드 캐치하는 데 되게 도움이 되고요.

제가 이제 여기다 써놓은 게 '외재화를 통해 현재 모델로 할 수 있는 continual learning 능력 부족을 우회하는 현상들이 보인다.' 인간이 context 관리하는 것과 유사하고 그걸 앞으로 수개월 안에 초인간적으로 잘할 가능성을 이제 상상하게 됐더라고요. 일단 되기 시작했으니까 Group Chat, 그거 요새 좀 빡세게 연습해 보고 있는데 아직 좀 생경하지만 되게 가능성이 느껴집니다. 이거는 한 주 더 묵혔다가 제가 좀 더 practice 쌓아서 소개해 드릴게요. 되게 흥미로운 포인트들이 있는데 딱 하나만 짚자면 여러 사람이 하니까 여러 사람에게 응대해야 되잖아요. 그래서 얘가 비동기적으로 그걸 다 queuing해서 답변을 하거든요. 그래서 대화하다가 그림을 그리는데 1번, 2번, 3번, 4번, 5번 한 번에 그리라고 하면 spawn돼서 쭉 다 얘기해 줍니다.

<span class="paragraph-timestamp" data-ts="55:09">55:09</span> **노정석** 별도의 instance로 다 돈다는 얘기죠.

<span class="paragraph-timestamp" data-ts="55:11">55:11</span> **최승준** 그렇죠. 아주 흥미로운 가능성들이 여기 들어 있고 대화 모드에 들어가 있는 에센스들이 있는데 다음에 한번 소개해 보겠습니다.

<span class="paragraph-timestamp" data-ts="55:17">55:17</span> **노정석** 네, 저는 이게 회사의 미래라고 생각합니다.

<span class="paragraph-timestamp" data-ts="55:19">55:19</span> **최승준** 짧게 얘기할 수가 없는 지금 상황이거든요.

<span class="paragraph-timestamp" data-ts="55:21">55:21</span> **노정석** 네, 나중에 한번 다루시죠.

## 클로징: 도망자 연합과 마무리    *55:23*

<span class="paragraph-timestamp" data-ts="55:28">55:28</span> **최승준** 오늘의 마무리입니다. 드디어 물론 이제 성현님은 연구자이시지만 AI 동호인일 뿐인 우리도 AI를 지렛대 삼아 더 좋은 토큰을 세상에 남기고 pre-training에 들어갈 수 있도록 기여할 수 있나, 더 좋은 세상에 기여할 수 있나.
근데 도망자 연합에 지원하시는 분들이 한결같이 하는 이야기가 기시감이 또 느껴져요. 비슷한 풍경을 보는 사람들과 대화해 보고 싶다. 좋은 얘기들 하고 싶다. 나누고 싶다, 이거죠.

<span class="paragraph-timestamp" data-ts="55:51">55:51</span> **노정석** 오늘은 이 정도에서 여운을 남기고 마무리를 하도록 하겠습니다.

<span class="paragraph-timestamp" data-ts="55:56">55:56</span> **최승준** 좋은 주말 되시기 바랍니다.

<span class="paragraph-timestamp" data-ts="56:02">56:02</span> **노정석** 성현 님이 오셔서 너무 좋고요. 성현 님이 계속 저희 이 토크에 껴서 이런저런 다른 관점의 피드백을 해 주시면 너무 좋을 것 같습니다. 감사합니다.

<span class="paragraph-timestamp" data-ts="56:06">56:06</span> **김성현** 감사합니다.